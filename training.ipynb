{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "800c30b4-1a47-4f60-9e31-cd0685b01565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/notebooks/Autoformer-main\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', batch_size=32, bucket_size=4, c_out=21, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='weather.csv', dec_in=21, des='Exp', devices='0,1,2', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', enc_in=21, factor=3, features='M', freq='h', gpu=0, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='Autoformer', model_id='weather_96_96', moving_avg=25, n_hashes=4, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/weather/', seq_len=96, target='OT', train_epochs=2, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "-------\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : weather_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 36696\n",
      "val 5175\n",
      "test 10444\n",
      "\titers: 100, epoch: 1 | loss: 1.4534090\n",
      "\tspeed: 0.2458s/iter; left time: 538.9685s\n",
      "\titers: 200, epoch: 1 | loss: 0.4052256\n",
      "\tspeed: 0.1399s/iter; left time: 292.8315s\n",
      "\titers: 300, epoch: 1 | loss: 0.3447830\n",
      "\tspeed: 0.1397s/iter; left time: 278.4509s\n",
      "\titers: 400, epoch: 1 | loss: 0.6342098\n",
      "\tspeed: 0.1397s/iter; left time: 264.5140s\n",
      "\titers: 500, epoch: 1 | loss: 0.4290570\n",
      "\tspeed: 0.1400s/iter; left time: 251.0734s\n",
      "\titers: 600, epoch: 1 | loss: 0.4598433\n",
      "\tspeed: 0.1397s/iter; left time: 236.5193s\n",
      "\titers: 700, epoch: 1 | loss: 0.4213922\n",
      "\tspeed: 0.1396s/iter; left time: 222.3589s\n",
      "\titers: 800, epoch: 1 | loss: 0.3904718\n",
      "\tspeed: 0.1399s/iter; left time: 208.8857s\n",
      "\titers: 900, epoch: 1 | loss: 0.3128994\n",
      "\tspeed: 0.1398s/iter; left time: 194.7550s\n",
      "\titers: 1000, epoch: 1 | loss: 0.3590854\n",
      "\tspeed: 0.1395s/iter; left time: 180.3494s\n",
      "\titers: 1100, epoch: 1 | loss: 1.2952460\n",
      "\tspeed: 0.1397s/iter; left time: 166.6874s\n",
      "Epoch: 1 cost time: 170.87385630607605\n",
      "Epoch: 1, Steps: 1146 | Train Loss: 0.4987228 Vali Loss: 0.5007752 Test Loss: 0.2508506\n",
      "Validation loss decreased (inf --> 0.500775).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2403387\n",
      "\tspeed: 0.5859s/iter; left time: 613.4863s\n",
      "\titers: 200, epoch: 2 | loss: 0.3357979\n",
      "\tspeed: 0.1397s/iter; left time: 132.3225s\n",
      "\titers: 300, epoch: 2 | loss: 0.2324897\n",
      "\tspeed: 0.1398s/iter; left time: 118.3697s\n",
      "\titers: 400, epoch: 2 | loss: 0.3604270\n",
      "\tspeed: 0.1400s/iter; left time: 104.6137s\n",
      "\titers: 500, epoch: 2 | loss: 0.3447027\n",
      "\tspeed: 0.1399s/iter; left time: 90.5194s\n",
      "\titers: 600, epoch: 2 | loss: 0.3634012\n",
      "\tspeed: 0.1400s/iter; left time: 76.5621s\n",
      "\titers: 700, epoch: 2 | loss: 0.2957060\n",
      "\tspeed: 0.1397s/iter; left time: 62.4578s\n",
      "\titers: 800, epoch: 2 | loss: 0.4785765\n",
      "\tspeed: 0.1397s/iter; left time: 48.4716s\n",
      "\titers: 900, epoch: 2 | loss: 0.4738994\n",
      "\tspeed: 0.1399s/iter; left time: 34.5661s\n",
      "\titers: 1000, epoch: 2 | loss: 0.3681854\n",
      "\tspeed: 0.1399s/iter; left time: 20.5614s\n",
      "\titers: 1100, epoch: 2 | loss: 0.3704407\n",
      "\tspeed: 0.1395s/iter; left time: 6.5583s\n",
      "Epoch: 2 cost time: 160.84171843528748\n",
      "Epoch: 2, Steps: 1146 | Train Loss: 0.4279946 Vali Loss: 0.5066220 Test Loss: 0.2733911\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      ">>>>>>>testing : weather_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 10444\n",
      "test shape: (10444, 96, 21) (10444, 96, 21)\n",
      "test shape: (10444, 96, 21) (10444, 96, 21)\n",
      "mse:0.2511812448501587, mae:0.32843998074531555\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', batch_size=32, bucket_size=4, c_out=21, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='weather.csv', dec_in=21, des='Exp', devices='0,1,2', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', enc_in=21, factor=3, features='M', freq='h', gpu=0, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='Autoformer', model_id='weather_96_192', moving_avg=25, n_hashes=4, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=192, root_path='./dataset/weather/', seq_len=96, target='OT', train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "-------\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : weather_96_192_Autoformer_custom_ftM_sl96_ll48_pl192_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 36600\n",
      "val 5079\n",
      "test 10348\n",
      "\titers: 100, epoch: 1 | loss: 0.6193966\n",
      "\tspeed: 0.2073s/iter; left time: 2349.4593s\n",
      "\titers: 200, epoch: 1 | loss: 0.6189556\n",
      "\tspeed: 0.1946s/iter; left time: 2186.0402s\n",
      "\titers: 300, epoch: 1 | loss: 0.6458966\n",
      "\tspeed: 0.1940s/iter; left time: 2158.9938s\n",
      "\titers: 400, epoch: 1 | loss: 0.7857165\n",
      "\tspeed: 0.1939s/iter; left time: 2138.6233s\n",
      "\titers: 500, epoch: 1 | loss: 0.5442438\n",
      "\tspeed: 0.1939s/iter; left time: 2119.8142s\n",
      "\titers: 600, epoch: 1 | loss: 0.6021955\n",
      "\tspeed: 0.1940s/iter; left time: 2101.5697s\n",
      "\titers: 700, epoch: 1 | loss: 0.6389098\n",
      "\tspeed: 0.1939s/iter; left time: 2080.5862s\n",
      "\titers: 800, epoch: 1 | loss: 0.4669038\n",
      "\tspeed: 0.1940s/iter; left time: 2062.5573s\n",
      "\titers: 900, epoch: 1 | loss: 0.9994487\n",
      "\tspeed: 0.1939s/iter; left time: 2041.4866s\n",
      "\titers: 1000, epoch: 1 | loss: 0.6131207\n",
      "\tspeed: 0.1939s/iter; left time: 2022.0895s\n",
      "\titers: 1100, epoch: 1 | loss: 0.5307980\n",
      "\tspeed: 0.1940s/iter; left time: 2004.5663s\n",
      "Epoch: 1 cost time: 223.2031865119934\n",
      "Epoch: 1, Steps: 1143 | Train Loss: 0.6288484 Vali Loss: 0.6243407 Test Loss: 0.3008201\n",
      "Validation loss decreased (inf --> 0.624341).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.7454643\n",
      "\tspeed: 0.8002s/iter; left time: 8152.9322s\n",
      "\titers: 200, epoch: 2 | loss: 0.5910727\n",
      "\tspeed: 0.1940s/iter; left time: 1957.4757s\n",
      "\titers: 300, epoch: 2 | loss: 0.5592793\n",
      "\tspeed: 0.1943s/iter; left time: 1940.9667s\n",
      "\titers: 400, epoch: 2 | loss: 0.4869172\n",
      "\tspeed: 0.1944s/iter; left time: 1922.0565s\n",
      "\titers: 500, epoch: 2 | loss: 0.5051412\n",
      "\tspeed: 0.1945s/iter; left time: 1904.1728s\n",
      "\titers: 600, epoch: 2 | loss: 0.9017061\n",
      "\tspeed: 0.1944s/iter; left time: 1883.2411s\n",
      "\titers: 700, epoch: 2 | loss: 0.4818937\n",
      "\tspeed: 0.1942s/iter; left time: 1861.5631s\n",
      "\titers: 800, epoch: 2 | loss: 0.4891100\n",
      "\tspeed: 0.1943s/iter; left time: 1843.0665s\n",
      "\titers: 900, epoch: 2 | loss: 0.5036669\n",
      "\tspeed: 0.1943s/iter; left time: 1824.3416s\n",
      "\titers: 1000, epoch: 2 | loss: 0.4391869\n",
      "\tspeed: 0.1943s/iter; left time: 1804.7414s\n",
      "\titers: 1100, epoch: 2 | loss: 0.5749756\n",
      "\tspeed: 0.1941s/iter; left time: 1783.7075s\n",
      "Epoch: 2 cost time: 222.68413519859314\n",
      "Epoch: 2, Steps: 1143 | Train Loss: 0.5681008 Vali Loss: 0.6159546 Test Loss: 0.3113479\n",
      "Validation loss decreased (0.624341 --> 0.615955).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.6100914\n",
      "\tspeed: 0.8067s/iter; left time: 7296.9700s\n",
      "\titers: 200, epoch: 3 | loss: 0.5715402\n",
      "\tspeed: 0.1944s/iter; left time: 1739.1385s\n",
      "\titers: 300, epoch: 3 | loss: 0.5585943\n",
      "\tspeed: 0.1942s/iter; left time: 1718.0631s\n",
      "\titers: 400, epoch: 3 | loss: 0.4902720\n",
      "\tspeed: 0.1944s/iter; left time: 1700.2620s\n",
      "\titers: 500, epoch: 3 | loss: 0.3727867\n",
      "\tspeed: 0.1946s/iter; left time: 1681.9201s\n",
      "\titers: 600, epoch: 3 | loss: 0.3741442\n",
      "\tspeed: 0.1947s/iter; left time: 1663.9239s\n",
      "\titers: 700, epoch: 3 | loss: 0.8087199\n",
      "\tspeed: 0.1947s/iter; left time: 1644.5400s\n",
      "\titers: 800, epoch: 3 | loss: 0.9552385\n",
      "\tspeed: 0.1945s/iter; left time: 1623.3877s\n",
      "\titers: 900, epoch: 3 | loss: 0.5081193\n",
      "\tspeed: 0.1942s/iter; left time: 1600.9844s\n",
      "\titers: 1000, epoch: 3 | loss: 0.6646433\n",
      "\tspeed: 0.1946s/iter; left time: 1584.7459s\n",
      "\titers: 1100, epoch: 3 | loss: 0.5161753\n",
      "\tspeed: 0.1941s/iter; left time: 1561.3393s\n",
      "Epoch: 3 cost time: 222.87096524238586\n",
      "Epoch: 3, Steps: 1143 | Train Loss: 0.5425487 Vali Loss: 0.6117448 Test Loss: 0.3130233\n",
      "Validation loss decreased (0.615955 --> 0.611745).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.4200509\n",
      "\tspeed: 0.8166s/iter; left time: 6452.8135s\n",
      "\titers: 200, epoch: 4 | loss: 0.3533139\n",
      "\tspeed: 0.1943s/iter; left time: 1516.1087s\n",
      "\titers: 300, epoch: 4 | loss: 0.4190277\n",
      "\tspeed: 0.1943s/iter; left time: 1496.1555s\n",
      "\titers: 500, epoch: 4 | loss: 0.5875095\n",
      "\tspeed: 0.1943s/iter; left time: 1457.8807s\n"
     ]
    }
   ],
   "source": [
    "# !pip install reformer_pytorch\n",
    "!bash ./scripts/Weather_script/Autoformer.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4292ea75-94f6-4b8a-b0fd-f6b8489c6c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May  1 14:39:01 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 510.60.02    Driver Version: 510.60.02    CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro P5000        Off  | 00000000:3B:00.0 Off |                  Off |\n",
      "| 26%   35C    P8    11W / 180W |    195MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Quadro P5000        Off  | 00000000:AF:00.0 Off |                  Off |\n",
      "| 26%   27C    P8     6W / 180W |      2MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Quadro P5000        Off  | 00000000:D8:00.0 Off |                  Off |\n",
      "| 26%   32C    P8     6W / 180W |      2MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2480      G   /usr/bin/X                         98MiB |\n",
      "|    0   N/A  N/A      3013      G   /usr/bin/gnome-shell                5MiB |\n",
      "|    0   N/A  N/A     14249      G   /usr/bin/gnome-shell               56MiB |\n",
      "|    0   N/A  N/A    158737      G   /usr/bin/gnome-shell               29MiB |\n",
      "|    0   N/A  N/A    159675      G   ...onda3/envs/env/bin/python        1MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15adc708-4660-4fc8-8478-f5dcdaeb9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# API key\n",
    "API_KEY = \"5c2dcc46834a46c1837a12eaadfe275a\"\n",
    "\n",
    "# Request parameters\n",
    "lat = -33.86\n",
    "lon = 151.209\n",
    "start_date = \"2023-04-01\"\n",
    "end_date = \"2023-05-01\"\n",
    "tz = \"local\"\n",
    "\n",
    "# API request URL\n",
    "url = f\"https://api.weatherbit.io/v2.0/history/subhourly?lat={lat}&lon={lon}&start_date={start_date}&end_date={end_date}&tz={tz}&key={API_KEY}\"\n",
    "\n",
    "# Send API request and get response\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check response status code\n",
    "if response.status_code == 200:\n",
    "    # Extract data from response\n",
    "    data = response.json()\n",
    "    # Print data\n",
    "    # print(data)\n",
    "    \n",
    "    with open(\"data11.json\", \"w\") as outfile:\n",
    "        json.dump(data, outfile)\n",
    "\n",
    "    \n",
    "# # Convert JSON data to a DataFrame\n",
    "#     df = pd.DataFrame.from_dict([data])\n",
    "\n",
    "# # Save data to CSV file\n",
    "#     df.to_csv('data.csv', index=False)\n",
    "    \n",
    "else:\n",
    "    # Print error message\n",
    "    print(f\"Error {response.status_code}: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b0a4438-c3b2-436f-a07b-359244bb1d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "# loop api for the limit of one month call per time\n",
    "# To obtain past 5 years weather data from weatherbit api(15 mins interval)\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import datetime\n",
    "import time\n",
    "# API key\n",
    "API_KEY = \"5c2dcc46834a46c1837a12eaadfe275a\"\n",
    "\n",
    "# Request parameters\n",
    "lat = -33.86\n",
    "lon = 151.209\n",
    "tz = \"local\"\n",
    "\n",
    "\n",
    "# Start and end dates\n",
    "start_date = datetime.date(2018, 5, 1)\n",
    "end_date = datetime.date(2022, 5, 1)\n",
    "\n",
    "# Loop through each month and make API call\n",
    "current_date = start_date\n",
    "i = 0\n",
    "while current_date < end_date:\n",
    "    # Calculate start and end dates for current month\n",
    "    current_month = current_date.strftime(\"%Y-%m\")\n",
    "    start_of_month = current_date.strftime(\"%Y-%m-%d\")\n",
    "    end_of_month = (current_date.replace(day=28) + datetime.timedelta(days=4)).strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    \n",
    "    url = f\"https://api.weatherbit.io/v2.0/history/subhourly?lat={lat}&lon={lon}&start_date={start_of_month}&end_date={end_of_month}&tz={tz}&key={API_KEY}\"\n",
    "\n",
    "    # Send API request and get response\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Check response status code\n",
    "    if response.status_code == 200:\n",
    "    # Extract data from response\n",
    "        data = response.json()\n",
    "    # Print data\n",
    "    # print(data)\n",
    "    \n",
    "        with open(f\"jsonData1/data{str(i)}.json\", \"w\") as outfile:\n",
    "            json.dump(data, outfile)\n",
    "    else:\n",
    "        print(f\"Error {response.status_code}: {response.text}\")\n",
    "\n",
    "    \n",
    "    # Move to next month\n",
    "    current_date = current_date.replace(day=28) + datetime.timedelta(days=4)\n",
    "    i = i+1\n",
    "\n",
    "    # Wait for some time before the next API call\n",
    "    time.sleep(1) # add some delay to avoid overloading the API server\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5184260-ac59-43ba-9ee3-aba15ccb596a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Columns: ['app_temp', 'azimuth', 'clouds', 'dewpt', 'dhi', 'dni', 'elev_angle', 'ghi', 'pod', 'precip_rate', 'pres', 'revision_status', 'rh', 'slp', 'snow_rate', 'solar_rad', 'temp', 'timestamp_local', 'timestamp_utc', 'ts', 'uv', 'vis', 'wind_dir', 'wind_gust_spd', 'wind_spd', 'weather.description', 'weather.code', 'weather.icon']\n",
      "Renamed Columns: ['app_temp', 'azimuth', 'clouds', 'dewpt', 'dhi', 'dni', 'elev_angle', 'ghi', 'pod', 'precip_rate', 'pres', 'revision_status', 'rh', 'slp', 'snow_rate', 'solar_rad', 'temp', 'timestamp_local', 'timestamp_utc', 'ts', 'uv', 'vis', 'wind_dir', 'wind_gust_spd', 'wind_spd', 'weather.description', 'weather.code', 'weather.icon']\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas\n",
    "\n",
    "\n",
    "def read_json(filename: str) -> dict:\n",
    "\n",
    "\ttry:\n",
    "\t\twith open(filename, \"r\") as f:\n",
    "\t\t\tdata = json.loads(f.read())\n",
    "\texcept:\n",
    "\t\traise Exception(f\"Reading {filename} file encountered an error\")\n",
    "\n",
    "\treturn data\n",
    "\n",
    "\n",
    "def create_dataframe(data: list) -> pandas.DataFrame:\n",
    "\n",
    "\t# Declare an empty dataframe to append records\n",
    "\tdataframe = pandas.DataFrame()\n",
    "\n",
    "\t# Looping through each record\n",
    "\tfor d in data:\n",
    "\t\t\n",
    "\t\t# Normalize the column levels\n",
    "\t\trecord = pandas.json_normalize(d)\n",
    "\t\t\n",
    "\t\t# Append it to the dataframe\n",
    "\t\tdataframe = pd.concat([dataframe, record], ignore_index=True)\n",
    "\n",
    "\n",
    "\n",
    "\treturn dataframe\n",
    "\n",
    "\n",
    "def main():\n",
    "\t# Read the JSON file as python dictionary\n",
    "\tdata = read_json(filename=\"data.json\")\n",
    "\t# print(data['data'])\n",
    "\n",
    "\t# Generate the dataframe for the array items in\n",
    "\t# details key\n",
    "\tdataframe = create_dataframe(data=data['data'])\n",
    "\n",
    "\t# Renaming columns of the dataframe\n",
    "\tprint(\"Normalized Columns:\", dataframe.columns.to_list())\n",
    "\n",
    "# \tdataframe.rename(columns={\n",
    "# \t\t\"results.school\": \"school\",\n",
    "# \t\t\"results.high_school\": \"high_school\",\n",
    "# \t\t\"results.graduation\": \"graduation\",\n",
    "# \t\t\"education.graduation.major\": \"grad_major\",\n",
    "# \t\t\"education.graduation.minor\": \"grad_minor\"\n",
    "# \t}, inplace=True)\n",
    "\n",
    "\tprint(\"Renamed Columns:\", dataframe.columns.to_list())\n",
    "\n",
    "\t# Convert dataframe to CSV\n",
    "\tdataframe.to_csv(\"details.csv\", index=False)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tmain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76cb5ca1-909c-4cce-b54d-a35f9b60455a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2976, 28)\n",
      "0\n",
      "(2880, 28)\n",
      "1\n",
      "(2976, 28)\n",
      "2\n",
      "(2976, 28)\n",
      "3\n",
      "(2876, 28)\n",
      "4\n",
      "(2976, 28)\n",
      "5\n",
      "(2880, 28)\n",
      "6\n",
      "(2976, 28)\n",
      "7\n",
      "(2976, 28)\n",
      "8\n",
      "(2688, 28)\n",
      "9\n",
      "(2980, 28)\n",
      "10\n",
      "(2880, 28)\n",
      "11\n",
      "(2976, 28)\n",
      "12\n",
      "(2880, 28)\n",
      "13\n",
      "(2976, 28)\n",
      "14\n",
      "(2976, 28)\n",
      "15\n",
      "(2876, 28)\n",
      "16\n",
      "(2976, 28)\n",
      "17\n",
      "(2880, 28)\n",
      "18\n",
      "(2976, 28)\n",
      "19\n",
      "(2976, 28)\n",
      "20\n",
      "(2784, 28)\n",
      "21\n",
      "(2980, 28)\n",
      "22\n",
      "(2880, 28)\n",
      "23\n",
      "(2976, 28)\n",
      "24\n",
      "(2880, 28)\n",
      "25\n",
      "(2976, 28)\n",
      "26\n",
      "(2976, 28)\n",
      "27\n",
      "(2876, 28)\n",
      "28\n",
      "(2976, 28)\n",
      "29\n",
      "(2880, 28)\n",
      "30\n",
      "(2976, 28)\n",
      "31\n",
      "(2976, 28)\n",
      "32\n",
      "(2688, 28)\n",
      "33\n",
      "(2980, 28)\n",
      "34\n",
      "(2880, 28)\n",
      "35\n",
      "(2976, 28)\n",
      "36\n",
      "(2880, 28)\n",
      "37\n",
      "(2976, 28)\n",
      "38\n",
      "(2976, 28)\n",
      "39\n",
      "(2876, 28)\n",
      "40\n",
      "(2976, 28)\n",
      "41\n",
      "(2880, 28)\n",
      "42\n",
      "(2976, 28)\n",
      "43\n",
      "(2976, 28)\n",
      "44\n",
      "(2688, 28)\n",
      "45\n",
      "(2980, 28)\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "# convert all json data into single csv file\n",
    "import json\n",
    "import pandas\n",
    "  \n",
    "  \n",
    "def read_json(filename: str) -> dict:\n",
    "  \n",
    "    try:\n",
    "        with open(filename, \"r\") as f:\n",
    "            data = json.loads(f.read())\n",
    "    except:\n",
    "        raise Exception(f\"Reading {filename} file encountered an error\")\n",
    "  \n",
    "    return data\n",
    "  \n",
    "  \n",
    "def create_dataframe(data: list) -> pandas.DataFrame:\n",
    "  \n",
    "    # Declare an empty dataframe to append records\n",
    "    dataframe = pandas.DataFrame()\n",
    "  \n",
    "    # Looping through each record\n",
    "    for d in data:\n",
    "          \n",
    "        # Normalize the column levels\n",
    "        record = pandas.json_normalize(d)\n",
    "        record = record.reindex(sorted(record.columns), axis=1)\n",
    "\n",
    "          \n",
    "        # Append it to the dataframe \n",
    "        dataframe = pandas.concat([dataframe, record], ignore_index=True)\n",
    "  \n",
    "    return dataframe\n",
    "  \n",
    "  \n",
    "def main():\n",
    "    # Read the JSON file as python dictionary \n",
    "    data = read_json(filename=\"jsonData1/data0.json\")\n",
    "    dataframe = create_dataframe(data=data['data'])\n",
    "    dataframe.to_csv(\"details1.csv\", index=False)\n",
    "    for i in range(47):\n",
    "        data = read_json(filename=f\"jsonData1/data{i+1}.json\")\n",
    "\n",
    "        # Generate the dataframe for the array items in \n",
    "        # details key \n",
    "        dataframe = create_dataframe(data=data['data'])\n",
    "        print(dataframe.shape)\n",
    "\n",
    "        # Renaming columns of the dataframe \n",
    "        # print(\"Normalized Columns:\", dataframe.columns.to_list())\n",
    "        print(i)\n",
    "\n",
    "\n",
    "        # Convert dataframe to CSV\n",
    "        dataframe.to_csv(\"details1.csv\", mode='a', index=False, header=False)\n",
    "  \n",
    "  \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33b270fa-8fc6-44d3-b05e-06c3b09870f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除重复时间数据\n",
    "import csv\n",
    "\n",
    "# 设置要删除的行数范围\n",
    "start_row = 140257\n",
    "end_row = 140352\n",
    "\n",
    "# 打开CSV文件并读取数据\n",
    "with open('details1.csv', 'r') as infile:\n",
    "    reader = csv.reader(infile)\n",
    "    data = [row for i, row in enumerate(reader) if i < start_row or i > end_row]\n",
    "\n",
    "# 将结果写回到原始CSV文件或者写入新的CSV文件\n",
    "with open('details2.csv', 'w', newline='') as outfile:\n",
    "    writer = csv.writer(outfile)\n",
    "    writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "847d67d8-a471-4115-8e1a-6519cec09bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['app_temp', 'azimuth', 'clouds', 'dewpt', 'dhi', 'dni', 'elev_angle',\n",
      "       'ghi', 'pod', 'precip_rate', 'pres', 'revision_status', 'rh', 'slp',\n",
      "       'snow_rate', 'solar_rad', 'temp', 'timestamp_local', 'timestamp_utc',\n",
      "       'ts', 'uv', 'vis', 'weather.code', 'weather.description',\n",
      "       'weather.icon', 'wind_dir', 'wind_gust_spd', 'wind_spd',\n",
      "       'Broken clouds', 'Clear Sky', 'Few clouds', 'Fog', 'Haze', 'Heavy rain',\n",
      "       'Light rain', 'Moderate rain', 'Overcast clouds', 'Scattered clouds',\n",
      "       'Thunderstorm with heavy rain'],\n",
      "      dtype='object')\n",
      "32\n"
     ]
    }
   ],
   "source": [
    "# preprocess csv data to remove useless columns and also one hot encode \n",
    "# weather desc string with float number\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('details1.csv', low_memory=False)\n",
    "one_hot_encoded = pd.get_dummies(df['weather.description'], dtype=float)\n",
    "# print(one_hot_encoded)\n",
    "df = pd.concat([df, one_hot_encoded], axis=1)\n",
    "# df.head()\n",
    "print(df.columns)\n",
    "df = df.drop(['timestamp_utc', 'weather.code','weather.description',\n",
    "       'weather.icon','revision_status','ts', 'pod'], axis=1)\n",
    "df = df.rename(columns={'timestamp_local': 'date'})\n",
    "\n",
    "print(len(df.columns))\n",
    "df.to_csv(\"processedData1.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd22cdb0-319e-43c7-b632-33e15443e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# append 2022-2023data to details2(2018-2022)data\n",
    "# processedData1.csv 2018-2022\n",
    "# processedData.csv 2022-2023\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv('dataset/weather/processedData1.csv')\n",
    "df2 = pd.read_csv('dataset/weather/processedData.csv')\n",
    "\n",
    "# Concatenate the two dataframes vertically\n",
    "result = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Write the result to a new CSV file\n",
    "result.to_csv('dataset/weather/data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b900d094-1a31-4a96-a96c-52801f91afbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['app_temp', 'azimuth', 'clouds', 'dewpt', 'dhi', 'dni', 'elev_angle',\n",
      "       'ghi', 'precip_rate', 'pres', 'rh', 'slp', 'snow_rate', 'solar_rad',\n",
      "       'temp', 'date', 'uv', 'vis', 'wind_dir', 'wind_gust_spd', 'wind_spd',\n",
      "       'Broken clouds', 'Clear Sky', 'Few clouds', 'Fog', 'Haze', 'Heavy rain',\n",
      "       'Light rain', 'Moderate rain', 'Overcast clouds', 'Scattered clouds',\n",
      "       'Thunderstorm with heavy rain'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "df1 = pd.read_csv('dataset/weather/processedData1.csv')\n",
    "print(df1.columns)\n",
    "df1.to_csv('col.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d0153a9-4a84-4bba-b264-e0c57a2fd913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/notebooks/Autoformer-main\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', batch_size=32, bucket_size=4, c_out=31, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='data.csv', dec_in=31, des='Exp', devices='0,1,2', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', enc_in=31, factor=3, features='M', freq='h', gpu=0, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='Autoformer', model_id='weather_96_96', moving_avg=25, n_hashes=4, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/weather/', seq_len=96, target='temp', train_epochs=5, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "-------\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : weather_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 122583\n",
      "val 17445\n",
      "test 34983\n",
      "\titers: 100, epoch: 1 | loss: 0.5753578\n",
      "\tspeed: 0.2455s/iter; left time: 4677.6194s\n",
      "\titers: 200, epoch: 1 | loss: 0.5461636\n",
      "\tspeed: 0.1396s/iter; left time: 2646.1850s\n",
      "\titers: 300, epoch: 1 | loss: 0.4508303\n",
      "\tspeed: 0.1402s/iter; left time: 2643.0339s\n",
      "\titers: 400, epoch: 1 | loss: 0.4557023\n",
      "\tspeed: 0.1401s/iter; left time: 2626.9128s\n",
      "\titers: 500, epoch: 1 | loss: 0.5417511\n",
      "\tspeed: 0.1401s/iter; left time: 2613.4311s\n",
      "\titers: 600, epoch: 1 | loss: 0.4532101\n",
      "\tspeed: 0.1402s/iter; left time: 2601.4101s\n",
      "\titers: 700, epoch: 1 | loss: 0.4662741\n",
      "\tspeed: 0.1402s/iter; left time: 2586.9540s\n",
      "\titers: 800, epoch: 1 | loss: 0.4218225\n",
      "\tspeed: 0.1400s/iter; left time: 2568.9853s\n",
      "\titers: 900, epoch: 1 | loss: 0.4060251\n",
      "\tspeed: 0.1398s/iter; left time: 2550.7320s\n",
      "\titers: 1000, epoch: 1 | loss: 0.5817932\n",
      "\tspeed: 0.1398s/iter; left time: 2537.5774s\n",
      "\titers: 1100, epoch: 1 | loss: 0.4451228\n",
      "\tspeed: 0.1399s/iter; left time: 2525.8260s\n",
      "\titers: 1200, epoch: 1 | loss: 0.7929990\n",
      "\tspeed: 0.1396s/iter; left time: 2506.7882s\n",
      "\titers: 1300, epoch: 1 | loss: 0.4323883\n",
      "\tspeed: 0.1399s/iter; left time: 2497.1567s\n",
      "\titers: 1400, epoch: 1 | loss: 0.4691082\n",
      "\tspeed: 0.1397s/iter; left time: 2480.0136s\n",
      "\titers: 1500, epoch: 1 | loss: 0.8705349\n",
      "\tspeed: 0.1400s/iter; left time: 2471.1683s\n",
      "\titers: 1600, epoch: 1 | loss: 0.5660939\n",
      "\tspeed: 0.1398s/iter; left time: 2452.9890s\n",
      "\titers: 1700, epoch: 1 | loss: 0.7205870\n",
      "\tspeed: 0.1398s/iter; left time: 2439.6587s\n",
      "\titers: 1800, epoch: 1 | loss: 0.7337484\n",
      "\tspeed: 0.1396s/iter; left time: 2422.9894s\n",
      "\titers: 1900, epoch: 1 | loss: 0.4951210\n",
      "\tspeed: 0.1397s/iter; left time: 2409.7458s\n",
      "\titers: 2000, epoch: 1 | loss: 0.5262341\n",
      "\tspeed: 0.1397s/iter; left time: 2396.0385s\n",
      "\titers: 2100, epoch: 1 | loss: 0.6563870\n",
      "\tspeed: 0.1397s/iter; left time: 2382.3771s\n",
      "\titers: 2200, epoch: 1 | loss: 0.4235313\n",
      "\tspeed: 0.1398s/iter; left time: 2370.0678s\n",
      "\titers: 2300, epoch: 1 | loss: 0.5724335\n",
      "\tspeed: 0.1397s/iter; left time: 2353.7270s\n",
      "\titers: 2400, epoch: 1 | loss: 0.7978716\n",
      "\tspeed: 0.1397s/iter; left time: 2339.3920s\n",
      "\titers: 2500, epoch: 1 | loss: 0.3906735\n",
      "\tspeed: 0.1400s/iter; left time: 2331.1144s\n",
      "\titers: 2600, epoch: 1 | loss: 0.4189597\n",
      "\tspeed: 0.1400s/iter; left time: 2316.9975s\n",
      "\titers: 2700, epoch: 1 | loss: 0.6952050\n",
      "\tspeed: 0.1399s/iter; left time: 2302.2338s\n",
      "\titers: 2800, epoch: 1 | loss: 0.4125500\n",
      "\tspeed: 0.1401s/iter; left time: 2289.9690s\n",
      "\titers: 2900, epoch: 1 | loss: 0.7895843\n",
      "\tspeed: 0.1400s/iter; left time: 2274.6256s\n",
      "\titers: 3000, epoch: 1 | loss: 0.6267738\n",
      "\tspeed: 0.1400s/iter; left time: 2260.6296s\n",
      "\titers: 3100, epoch: 1 | loss: 0.4329271\n",
      "\tspeed: 0.1398s/iter; left time: 2244.6228s\n",
      "\titers: 3200, epoch: 1 | loss: 0.3847649\n",
      "\tspeed: 0.1398s/iter; left time: 2230.0971s\n",
      "\titers: 3300, epoch: 1 | loss: 0.4210019\n",
      "\tspeed: 0.1399s/iter; left time: 2217.4690s\n",
      "\titers: 3400, epoch: 1 | loss: 0.5536305\n",
      "\tspeed: 0.1399s/iter; left time: 2204.0961s\n",
      "\titers: 3500, epoch: 1 | loss: 0.5383829\n",
      "\tspeed: 0.1401s/iter; left time: 2193.0372s\n",
      "\titers: 3600, epoch: 1 | loss: 0.5628433\n",
      "\tspeed: 0.1401s/iter; left time: 2178.3075s\n",
      "\titers: 3700, epoch: 1 | loss: 0.6399847\n",
      "\tspeed: 0.1400s/iter; left time: 2162.7449s\n",
      "\titers: 3800, epoch: 1 | loss: 0.3633434\n",
      "\tspeed: 0.1400s/iter; left time: 2148.3869s\n",
      "Epoch: 1 cost time: 546.4799444675446\n",
      "Epoch: 1, Steps: 3830 | Train Loss: 0.5553831 Vali Loss: 3.3768246 Test Loss: 1.6055796\n",
      "Validation loss decreased (inf --> 3.376825).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8119372\n",
      "\tspeed: 1.3588s/iter; left time: 20681.6934s\n",
      "\titers: 200, epoch: 2 | loss: 0.6389675\n",
      "\tspeed: 0.1403s/iter; left time: 2121.7197s\n",
      "\titers: 300, epoch: 2 | loss: 0.5558077\n",
      "\tspeed: 0.1402s/iter; left time: 2105.8035s\n",
      "\titers: 400, epoch: 2 | loss: 0.3835403\n",
      "\tspeed: 0.1399s/iter; left time: 2087.0055s\n",
      "\titers: 500, epoch: 2 | loss: 0.4694400\n",
      "\tspeed: 0.1399s/iter; left time: 2073.3933s\n",
      "\titers: 600, epoch: 2 | loss: 0.4058161\n",
      "\tspeed: 0.1401s/iter; left time: 2061.6817s\n",
      "\titers: 700, epoch: 2 | loss: 0.5740527\n",
      "\tspeed: 0.1399s/iter; left time: 2046.0582s\n",
      "\titers: 800, epoch: 2 | loss: 0.4365574\n",
      "\tspeed: 0.1400s/iter; left time: 2033.5549s\n",
      "\titers: 900, epoch: 2 | loss: 0.3579036\n",
      "\tspeed: 0.1401s/iter; left time: 2020.5420s\n",
      "\titers: 1000, epoch: 2 | loss: 0.7082798\n",
      "\tspeed: 0.1400s/iter; left time: 2005.3588s\n",
      "\titers: 1100, epoch: 2 | loss: 0.5073228\n",
      "\tspeed: 0.1402s/iter; left time: 1993.2592s\n",
      "\titers: 1200, epoch: 2 | loss: 0.9501532\n",
      "\tspeed: 0.1403s/iter; left time: 1981.2855s\n",
      "\titers: 1300, epoch: 2 | loss: 0.4067529\n",
      "\tspeed: 0.1400s/iter; left time: 1963.4183s\n",
      "\titers: 1400, epoch: 2 | loss: 0.5829435\n",
      "\tspeed: 0.1400s/iter; left time: 1949.0473s\n",
      "\titers: 1500, epoch: 2 | loss: 0.5609763\n",
      "\tspeed: 0.1401s/iter; left time: 1936.4408s\n",
      "\titers: 1600, epoch: 2 | loss: 0.3667990\n",
      "\tspeed: 0.1405s/iter; left time: 1928.4468s\n",
      "\titers: 1700, epoch: 2 | loss: 0.3689135\n",
      "\tspeed: 0.1401s/iter; left time: 1908.0328s\n",
      "\titers: 1800, epoch: 2 | loss: 0.3181430\n",
      "\tspeed: 0.1401s/iter; left time: 1894.0372s\n",
      "\titers: 1900, epoch: 2 | loss: 0.6581763\n",
      "\tspeed: 0.1399s/iter; left time: 1877.4319s\n",
      "\titers: 2000, epoch: 2 | loss: 0.4526697\n",
      "\tspeed: 0.1404s/iter; left time: 1869.8703s\n",
      "\titers: 2100, epoch: 2 | loss: 0.4997837\n",
      "\tspeed: 0.1403s/iter; left time: 1854.7053s\n",
      "\titers: 2200, epoch: 2 | loss: 0.3386378\n",
      "\tspeed: 0.1401s/iter; left time: 1837.8886s\n",
      "\titers: 2300, epoch: 2 | loss: 0.4314905\n",
      "\tspeed: 0.1400s/iter; left time: 1823.4834s\n",
      "\titers: 2400, epoch: 2 | loss: 0.3120950\n",
      "\tspeed: 0.1401s/iter; left time: 1810.2390s\n",
      "\titers: 2500, epoch: 2 | loss: 0.2658598\n",
      "\tspeed: 0.1401s/iter; left time: 1796.7261s\n",
      "\titers: 2600, epoch: 2 | loss: 0.3962513\n",
      "\tspeed: 0.1401s/iter; left time: 1782.2772s\n",
      "\titers: 2700, epoch: 2 | loss: 0.3890770\n",
      "\tspeed: 0.1404s/iter; left time: 1772.1348s\n",
      "\titers: 2800, epoch: 2 | loss: 0.4509861\n",
      "\tspeed: 0.1404s/iter; left time: 1758.3052s\n",
      "\titers: 2900, epoch: 2 | loss: 0.3018373\n",
      "\tspeed: 0.1401s/iter; left time: 1740.2047s\n",
      "\titers: 3000, epoch: 2 | loss: 0.2974148\n",
      "\tspeed: 0.1402s/iter; left time: 1727.9119s\n",
      "\titers: 3100, epoch: 2 | loss: 0.5090529\n",
      "\tspeed: 0.1402s/iter; left time: 1713.0764s\n",
      "\titers: 3200, epoch: 2 | loss: 0.3624553\n",
      "\tspeed: 0.1401s/iter; left time: 1698.7275s\n",
      "\titers: 3300, epoch: 2 | loss: 0.2800969\n",
      "\tspeed: 0.1404s/iter; left time: 1688.0826s\n",
      "\titers: 3400, epoch: 2 | loss: 0.3895590\n",
      "\tspeed: 0.1403s/iter; left time: 1672.4989s\n",
      "\titers: 3500, epoch: 2 | loss: 0.3158388\n",
      "\tspeed: 0.1401s/iter; left time: 1656.3745s\n",
      "\titers: 3600, epoch: 2 | loss: 0.3636321\n",
      "\tspeed: 0.1401s/iter; left time: 1642.2506s\n",
      "\titers: 3700, epoch: 2 | loss: 0.4840307\n",
      "\tspeed: 0.1400s/iter; left time: 1626.7020s\n",
      "\titers: 3800, epoch: 2 | loss: 0.3303666\n",
      "\tspeed: 0.1398s/iter; left time: 1611.1090s\n",
      "Epoch: 2 cost time: 537.4085273742676\n",
      "Epoch: 2, Steps: 3830 | Train Loss: 0.4176842 Vali Loss: 3.3742883 Test Loss: 1.6383977\n",
      "Validation loss decreased (3.376825 --> 3.374288).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2966325\n",
      "\tspeed: 1.3916s/iter; left time: 15851.8186s\n",
      "\titers: 200, epoch: 3 | loss: 0.2674719\n",
      "\tspeed: 0.1398s/iter; left time: 1579.0143s\n",
      "\titers: 300, epoch: 3 | loss: 0.3963054\n",
      "\tspeed: 0.1401s/iter; left time: 1568.2316s\n",
      "\titers: 400, epoch: 3 | loss: 0.4237168\n",
      "\tspeed: 0.1399s/iter; left time: 1551.5716s\n",
      "\titers: 500, epoch: 3 | loss: 0.3216219\n",
      "\tspeed: 0.1397s/iter; left time: 1534.9847s\n",
      "\titers: 600, epoch: 3 | loss: 0.3224137\n",
      "\tspeed: 0.1400s/iter; left time: 1524.8887s\n",
      "\titers: 700, epoch: 3 | loss: 0.3900728\n",
      "\tspeed: 0.1401s/iter; left time: 1512.3474s\n",
      "\titers: 800, epoch: 3 | loss: 0.3698943\n",
      "\tspeed: 0.1398s/iter; left time: 1494.5466s\n",
      "\titers: 900, epoch: 3 | loss: 0.2783012\n",
      "\tspeed: 0.1396s/iter; left time: 1478.3331s\n",
      "\titers: 1000, epoch: 3 | loss: 0.2663952\n",
      "\tspeed: 0.1398s/iter; left time: 1467.1235s\n",
      "\titers: 1100, epoch: 3 | loss: 0.2541041\n",
      "\tspeed: 0.1398s/iter; left time: 1452.6073s\n",
      "\titers: 1200, epoch: 3 | loss: 0.2580494\n",
      "\tspeed: 0.1399s/iter; left time: 1439.6571s\n",
      "\titers: 1300, epoch: 3 | loss: 0.3666410\n",
      "\tspeed: 0.1399s/iter; left time: 1425.6611s\n",
      "\titers: 1400, epoch: 3 | loss: 0.2797347\n",
      "\tspeed: 0.1398s/iter; left time: 1410.7066s\n",
      "\titers: 1500, epoch: 3 | loss: 0.2393709\n",
      "\tspeed: 0.1399s/iter; left time: 1397.8776s\n",
      "\titers: 1600, epoch: 3 | loss: 0.3401826\n",
      "\tspeed: 0.1400s/iter; left time: 1384.2462s\n",
      "\titers: 1700, epoch: 3 | loss: 0.3683532\n",
      "\tspeed: 0.1396s/iter; left time: 1366.4546s\n",
      "\titers: 1800, epoch: 3 | loss: 0.3024172\n",
      "\tspeed: 0.1403s/iter; left time: 1359.9128s\n",
      "\titers: 1900, epoch: 3 | loss: 0.3140296\n",
      "\tspeed: 0.1399s/iter; left time: 1341.9821s\n",
      "\titers: 2000, epoch: 3 | loss: 0.3645380\n",
      "\tspeed: 0.1400s/iter; left time: 1329.0838s\n",
      "\titers: 2100, epoch: 3 | loss: 0.4255055\n",
      "\tspeed: 0.1402s/iter; left time: 1316.5092s\n",
      "\titers: 2200, epoch: 3 | loss: 0.3588843\n",
      "\tspeed: 0.1400s/iter; left time: 1301.1077s\n",
      "\titers: 2300, epoch: 3 | loss: 0.2708682\n",
      "\tspeed: 0.1404s/iter; left time: 1290.3838s\n",
      "\titers: 2400, epoch: 3 | loss: 0.3413360\n",
      "\tspeed: 0.1403s/iter; left time: 1275.1651s\n",
      "\titers: 2500, epoch: 3 | loss: 0.2945275\n",
      "\tspeed: 0.1402s/iter; left time: 1260.1041s\n",
      "\titers: 2600, epoch: 3 | loss: 0.3563632\n",
      "\tspeed: 0.1399s/iter; left time: 1243.8580s\n",
      "\titers: 2700, epoch: 3 | loss: 0.4129357\n",
      "\tspeed: 0.1398s/iter; left time: 1228.8552s\n",
      "\titers: 2800, epoch: 3 | loss: 0.3172240\n",
      "\tspeed: 0.1402s/iter; left time: 1218.3344s\n",
      "\titers: 2900, epoch: 3 | loss: 0.2340666\n",
      "\tspeed: 0.1400s/iter; left time: 1202.9965s\n",
      "\titers: 3000, epoch: 3 | loss: 0.2832348\n",
      "\tspeed: 0.1400s/iter; left time: 1188.6474s\n",
      "\titers: 3100, epoch: 3 | loss: 0.2738055\n",
      "\tspeed: 0.1398s/iter; left time: 1173.4532s\n",
      "\titers: 3200, epoch: 3 | loss: 0.3823875\n",
      "\tspeed: 0.1398s/iter; left time: 1158.8612s\n",
      "\titers: 3300, epoch: 3 | loss: 0.4054945\n",
      "\tspeed: 0.1400s/iter; left time: 1146.7592s\n",
      "\titers: 3400, epoch: 3 | loss: 0.2100617\n",
      "\tspeed: 0.1402s/iter; left time: 1134.7605s\n",
      "\titers: 3500, epoch: 3 | loss: 0.2819744\n",
      "\tspeed: 0.1399s/iter; left time: 1118.1586s\n",
      "\titers: 3600, epoch: 3 | loss: 0.3001733\n",
      "\tspeed: 0.1405s/iter; left time: 1108.5773s\n",
      "\titers: 3700, epoch: 3 | loss: 0.3174419\n",
      "\tspeed: 0.1398s/iter; left time: 1089.2103s\n",
      "\titers: 3800, epoch: 3 | loss: 0.2680958\n",
      "\tspeed: 0.1398s/iter; left time: 1075.4729s\n",
      "Epoch: 3 cost time: 536.8683166503906\n",
      "Epoch: 3, Steps: 3830 | Train Loss: 0.3343618 Vali Loss: 3.4173317 Test Loss: 1.6570877\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2224286\n",
      "\tspeed: 1.4217s/iter; left time: 10749.1688s\n",
      "\titers: 200, epoch: 4 | loss: 0.4102194\n",
      "\tspeed: 0.1401s/iter; left time: 1045.2183s\n",
      "\titers: 300, epoch: 4 | loss: 0.2762715\n",
      "\tspeed: 0.1402s/iter; left time: 1031.8220s\n",
      "\titers: 400, epoch: 4 | loss: 0.3051192\n",
      "\tspeed: 0.1399s/iter; left time: 1015.8795s\n",
      "\titers: 500, epoch: 4 | loss: 0.3677411\n",
      "\tspeed: 0.1402s/iter; left time: 1004.0649s\n",
      "\titers: 600, epoch: 4 | loss: 0.2052501\n",
      "\tspeed: 0.1400s/iter; left time: 988.3663s\n",
      "\titers: 700, epoch: 4 | loss: 0.3397700\n",
      "\tspeed: 0.1399s/iter; left time: 973.7754s\n",
      "\titers: 800, epoch: 4 | loss: 0.3678490\n",
      "\tspeed: 0.1399s/iter; left time: 959.8938s\n",
      "\titers: 900, epoch: 4 | loss: 0.2501621\n",
      "\tspeed: 0.1398s/iter; left time: 945.0142s\n",
      "\titers: 1000, epoch: 4 | loss: 0.3062271\n",
      "\tspeed: 0.1398s/iter; left time: 931.4693s\n",
      "\titers: 1100, epoch: 4 | loss: 0.2071303\n",
      "\tspeed: 0.1401s/iter; left time: 919.3238s\n",
      "\titers: 1200, epoch: 4 | loss: 0.2721364\n",
      "\tspeed: 0.1401s/iter; left time: 905.2496s\n",
      "\titers: 1300, epoch: 4 | loss: 0.3829756\n",
      "\tspeed: 0.1401s/iter; left time: 891.3994s\n",
      "\titers: 1400, epoch: 4 | loss: 0.2583358\n",
      "\tspeed: 0.1399s/iter; left time: 876.2223s\n",
      "\titers: 1500, epoch: 4 | loss: 0.3207777\n",
      "\tspeed: 0.1400s/iter; left time: 862.4635s\n",
      "\titers: 1600, epoch: 4 | loss: 0.3691063\n",
      "\tspeed: 0.1399s/iter; left time: 848.1323s\n",
      "\titers: 1700, epoch: 4 | loss: 0.3031265\n",
      "\tspeed: 0.1400s/iter; left time: 834.5213s\n",
      "\titers: 1800, epoch: 4 | loss: 0.2719689\n",
      "\tspeed: 0.1399s/iter; left time: 819.9728s\n",
      "\titers: 1900, epoch: 4 | loss: 0.3902126\n",
      "\tspeed: 0.1400s/iter; left time: 806.7042s\n",
      "\titers: 2000, epoch: 4 | loss: 0.3884917\n",
      "\tspeed: 0.1398s/iter; left time: 791.3683s\n",
      "\titers: 2100, epoch: 4 | loss: 0.2078473\n",
      "\tspeed: 0.1399s/iter; left time: 777.7653s\n",
      "\titers: 2200, epoch: 4 | loss: 0.3595284\n",
      "\tspeed: 0.1398s/iter; left time: 763.6863s\n",
      "\titers: 2300, epoch: 4 | loss: 0.2200029\n",
      "\tspeed: 0.1398s/iter; left time: 749.4146s\n",
      "\titers: 2400, epoch: 4 | loss: 0.5033095\n",
      "\tspeed: 0.1399s/iter; left time: 735.8827s\n",
      "\titers: 2500, epoch: 4 | loss: 0.2108107\n",
      "\tspeed: 0.1399s/iter; left time: 721.8344s\n",
      "\titers: 2600, epoch: 4 | loss: 0.2360582\n",
      "\tspeed: 0.1401s/iter; left time: 709.1810s\n",
      "\titers: 2700, epoch: 4 | loss: 0.2384529\n",
      "\tspeed: 0.1402s/iter; left time: 695.5547s\n",
      "\titers: 2800, epoch: 4 | loss: 0.2811828\n",
      "\tspeed: 0.1396s/iter; left time: 678.6929s\n",
      "\titers: 2900, epoch: 4 | loss: 0.2728275\n",
      "\tspeed: 0.1399s/iter; left time: 666.0590s\n",
      "\titers: 3000, epoch: 4 | loss: 0.2034261\n",
      "\tspeed: 0.1400s/iter; left time: 652.7726s\n",
      "\titers: 3100, epoch: 4 | loss: 0.2264251\n",
      "\tspeed: 0.1400s/iter; left time: 638.6433s\n",
      "\titers: 3200, epoch: 4 | loss: 0.3999392\n",
      "\tspeed: 0.1405s/iter; left time: 626.9506s\n",
      "\titers: 3300, epoch: 4 | loss: 0.2486382\n",
      "\tspeed: 0.1402s/iter; left time: 611.3794s\n",
      "\titers: 3400, epoch: 4 | loss: 0.3067204\n",
      "\tspeed: 0.1402s/iter; left time: 597.3648s\n",
      "\titers: 3500, epoch: 4 | loss: 0.2630483\n",
      "\tspeed: 0.1400s/iter; left time: 582.4810s\n",
      "\titers: 3600, epoch: 4 | loss: 0.3559924\n",
      "\tspeed: 0.1403s/iter; left time: 569.5881s\n",
      "\titers: 3700, epoch: 4 | loss: 0.2830216\n",
      "\tspeed: 0.1400s/iter; left time: 554.5617s\n",
      "\titers: 3800, epoch: 4 | loss: 0.3120352\n",
      "\tspeed: 0.1399s/iter; left time: 540.1924s\n",
      "Epoch: 4 cost time: 536.9323863983154\n",
      "Epoch: 4, Steps: 3830 | Train Loss: 0.2984938 Vali Loss: 3.4035246 Test Loss: 1.6573368\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2387182\n",
      "\tspeed: 1.3751s/iter; left time: 5130.3997s\n",
      "\titers: 200, epoch: 5 | loss: 0.2555111\n",
      "\tspeed: 0.1400s/iter; left time: 508.4462s\n",
      "\titers: 300, epoch: 5 | loss: 0.2183785\n",
      "\tspeed: 0.1400s/iter; left time: 494.2860s\n",
      "\titers: 400, epoch: 5 | loss: 0.3257182\n",
      "\tspeed: 0.1401s/iter; left time: 480.5249s\n",
      "\titers: 500, epoch: 5 | loss: 0.5070591\n",
      "\tspeed: 0.1400s/iter; left time: 466.4517s\n",
      "\titers: 600, epoch: 5 | loss: 0.2690222\n",
      "\tspeed: 0.1399s/iter; left time: 452.1658s\n",
      "\titers: 700, epoch: 5 | loss: 0.2997423\n",
      "\tspeed: 0.1399s/iter; left time: 438.1675s\n",
      "\titers: 800, epoch: 5 | loss: 0.3048397\n",
      "\tspeed: 0.1401s/iter; left time: 424.5264s\n",
      "\titers: 900, epoch: 5 | loss: 0.2779144\n",
      "\tspeed: 0.1401s/iter; left time: 410.6776s\n",
      "\titers: 1000, epoch: 5 | loss: 0.2641024\n",
      "\tspeed: 0.1402s/iter; left time: 396.9136s\n",
      "\titers: 1100, epoch: 5 | loss: 0.2635452\n",
      "\tspeed: 0.1401s/iter; left time: 382.4838s\n",
      "\titers: 1200, epoch: 5 | loss: 0.3594373\n",
      "\tspeed: 0.1401s/iter; left time: 368.5862s\n",
      "\titers: 1300, epoch: 5 | loss: 0.2403542\n",
      "\tspeed: 0.1400s/iter; left time: 354.3019s\n",
      "\titers: 1400, epoch: 5 | loss: 0.2290440\n",
      "\tspeed: 0.1402s/iter; left time: 340.7256s\n",
      "\titers: 1500, epoch: 5 | loss: 0.3438555\n",
      "\tspeed: 0.1403s/iter; left time: 327.0667s\n",
      "\titers: 1600, epoch: 5 | loss: 0.2828433\n",
      "\tspeed: 0.1402s/iter; left time: 312.7890s\n",
      "\titers: 1700, epoch: 5 | loss: 0.3576101\n",
      "\tspeed: 0.1400s/iter; left time: 298.3337s\n",
      "\titers: 1800, epoch: 5 | loss: 0.2083416\n",
      "\tspeed: 0.1399s/iter; left time: 284.2021s\n",
      "\titers: 1900, epoch: 5 | loss: 0.2037132\n",
      "\tspeed: 0.1399s/iter; left time: 270.1619s\n",
      "\titers: 2000, epoch: 5 | loss: 0.2742983\n",
      "\tspeed: 0.1401s/iter; left time: 256.5176s\n",
      "\titers: 2100, epoch: 5 | loss: 0.3341356\n",
      "\tspeed: 0.1399s/iter; left time: 242.2091s\n",
      "\titers: 2200, epoch: 5 | loss: 0.3271598\n",
      "\tspeed: 0.1400s/iter; left time: 228.4214s\n",
      "\titers: 2300, epoch: 5 | loss: 0.2913807\n",
      "\tspeed: 0.1400s/iter; left time: 214.4055s\n",
      "\titers: 2400, epoch: 5 | loss: 0.2287598\n",
      "\tspeed: 0.1401s/iter; left time: 200.4447s\n",
      "\titers: 2500, epoch: 5 | loss: 0.3945938\n",
      "\tspeed: 0.1400s/iter; left time: 186.2765s\n",
      "\titers: 2600, epoch: 5 | loss: 0.2249884\n",
      "\tspeed: 0.1400s/iter; left time: 172.3187s\n",
      "\titers: 2700, epoch: 5 | loss: 0.2117553\n",
      "\tspeed: 0.1401s/iter; left time: 158.4559s\n",
      "\titers: 2800, epoch: 5 | loss: 0.3654656\n",
      "\tspeed: 0.1401s/iter; left time: 144.4689s\n",
      "\titers: 2900, epoch: 5 | loss: 0.2890962\n",
      "\tspeed: 0.1399s/iter; left time: 130.2476s\n",
      "\titers: 3000, epoch: 5 | loss: 0.2424752\n",
      "\tspeed: 0.1399s/iter; left time: 116.2874s\n",
      "\titers: 3100, epoch: 5 | loss: 0.2867770\n",
      "\tspeed: 0.1399s/iter; left time: 102.2990s\n",
      "\titers: 3200, epoch: 5 | loss: 0.3065182\n",
      "\tspeed: 0.1400s/iter; left time: 88.3579s\n",
      "\titers: 3300, epoch: 5 | loss: 0.3465473\n",
      "\tspeed: 0.1400s/iter; left time: 74.3495s\n",
      "\titers: 3400, epoch: 5 | loss: 0.2794383\n",
      "\tspeed: 0.1401s/iter; left time: 60.3865s\n",
      "\titers: 3500, epoch: 5 | loss: 0.2193588\n",
      "\tspeed: 0.1399s/iter; left time: 46.3096s\n",
      "\titers: 3600, epoch: 5 | loss: 0.3340531\n",
      "\tspeed: 0.1399s/iter; left time: 32.3121s\n",
      "\titers: 3700, epoch: 5 | loss: 0.2468617\n",
      "\tspeed: 0.1399s/iter; left time: 18.3280s\n",
      "\titers: 3800, epoch: 5 | loss: 0.3409521\n",
      "\tspeed: 0.1399s/iter; left time: 4.3377s\n",
      "Epoch: 5 cost time: 537.0708842277527\n",
      "Epoch: 5, Steps: 3830 | Train Loss: 0.2808995 Vali Loss: 3.4210658 Test Loss: 1.6608498\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : weather_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 34983\n",
      "test shape: (34983, 96, 31) (34983, 96, 31)\n",
      "test shape: (34983, 96, 31) (34983, 96, 31)\n",
      "mse:1.6389776468276978, mae:0.5460250973701477\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "!bash ./scripts/Weather_script/myAutoformer.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8cddd46-53ea-4c3f-b4ce-241112d85d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/notebooks/Autoformer-main\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', batch_size=32, bucket_size=4, c_out=31, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='data.csv', dec_in=31, des='Exp', devices='0,1,2', distil=True, do_predict=False, dropout=0.05, e_layers=2, embed='timeF', enc_in=31, factor=3, features='M', freq='h', gpu=0, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='Autoformer', model_id='weather_96_96', moving_avg=25, n_hashes=4, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/weather/', seq_len=96, target='temp', train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "-------\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : weather_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 122583\n",
      "val 17445\n",
      "test 34983\n",
      "\titers: 100, epoch: 1 | loss: 0.5753577\n",
      "\tspeed: 0.2462s/iter; left time: 9403.3223s\n",
      "\titers: 200, epoch: 1 | loss: 0.5461820\n",
      "\tspeed: 0.1400s/iter; left time: 5332.7531s\n",
      "\titers: 300, epoch: 1 | loss: 0.4509969\n",
      "\tspeed: 0.1399s/iter; left time: 5317.4612s\n",
      "\titers: 400, epoch: 1 | loss: 0.4565855\n",
      "\tspeed: 0.1397s/iter; left time: 5293.0044s\n",
      "\titers: 500, epoch: 1 | loss: 0.5408784\n",
      "\tspeed: 0.1398s/iter; left time: 5283.1256s\n",
      "\titers: 600, epoch: 1 | loss: 0.4505438\n",
      "\tspeed: 0.1402s/iter; left time: 5285.3534s\n",
      "\titers: 700, epoch: 1 | loss: 0.4616419\n",
      "\tspeed: 0.1402s/iter; left time: 5271.7566s\n",
      "\titers: 800, epoch: 1 | loss: 0.4209445\n",
      "\tspeed: 0.1399s/iter; left time: 5247.0611s\n",
      "\titers: 900, epoch: 1 | loss: 0.4078067\n",
      "\tspeed: 0.1397s/iter; left time: 5224.3635s\n",
      "\titers: 1000, epoch: 1 | loss: 0.5803522\n",
      "\tspeed: 0.1398s/iter; left time: 5216.2168s\n",
      "\titers: 1100, epoch: 1 | loss: 0.4484428\n",
      "\tspeed: 0.1399s/iter; left time: 5203.2285s\n",
      "\titers: 1200, epoch: 1 | loss: 0.7831229\n",
      "\tspeed: 0.1396s/iter; left time: 5179.6436s\n",
      "\titers: 1300, epoch: 1 | loss: 0.4356762\n",
      "\tspeed: 0.1396s/iter; left time: 5167.0395s\n",
      "\titers: 1400, epoch: 1 | loss: 0.4740589\n",
      "\tspeed: 0.1397s/iter; left time: 5154.2046s\n",
      "\titers: 1500, epoch: 1 | loss: 0.8699849\n",
      "\tspeed: 0.1399s/iter; left time: 5147.4626s\n",
      "\titers: 1600, epoch: 1 | loss: 0.5655507\n",
      "\tspeed: 0.1396s/iter; left time: 5124.4668s\n",
      "\titers: 1700, epoch: 1 | loss: 0.7184133\n",
      "\tspeed: 0.1397s/iter; left time: 5111.6293s\n",
      "\titers: 1800, epoch: 1 | loss: 0.7329407\n",
      "\tspeed: 0.1398s/iter; left time: 5104.5990s\n",
      "\titers: 1900, epoch: 1 | loss: 0.4936909\n",
      "\tspeed: 0.1398s/iter; left time: 5089.9390s\n",
      "\titers: 2000, epoch: 1 | loss: 0.5334795\n",
      "\tspeed: 0.1401s/iter; left time: 5084.4506s\n",
      "\titers: 2100, epoch: 1 | loss: 0.6544390\n",
      "\tspeed: 0.1403s/iter; left time: 5079.4392s\n",
      "\titers: 2200, epoch: 1 | loss: 0.4300763\n",
      "\tspeed: 0.1399s/iter; left time: 5051.3435s\n",
      "\titers: 2300, epoch: 1 | loss: 0.5770658\n",
      "\tspeed: 0.1399s/iter; left time: 5034.8003s\n",
      "\titers: 2400, epoch: 1 | loss: 0.8040870\n",
      "\tspeed: 0.1403s/iter; left time: 5036.4542s\n",
      "\titers: 2500, epoch: 1 | loss: 0.3857679\n",
      "\tspeed: 0.1399s/iter; left time: 5010.2444s\n",
      "\titers: 2600, epoch: 1 | loss: 0.4176323\n",
      "\tspeed: 0.1399s/iter; left time: 4995.9195s\n",
      "\titers: 2700, epoch: 1 | loss: 0.7094598\n",
      "\tspeed: 0.1399s/iter; left time: 4980.7533s\n",
      "\titers: 2800, epoch: 1 | loss: 0.4089356\n",
      "\tspeed: 0.1402s/iter; left time: 4975.6913s\n",
      "\titers: 2900, epoch: 1 | loss: 0.7930364\n",
      "\tspeed: 0.1402s/iter; left time: 4964.8592s\n",
      "\titers: 3000, epoch: 1 | loss: 0.6355129\n",
      "\tspeed: 0.1402s/iter; left time: 4947.4802s\n",
      "\titers: 3100, epoch: 1 | loss: 0.4346834\n",
      "\tspeed: 0.1403s/iter; left time: 4939.1627s\n",
      "\titers: 3200, epoch: 1 | loss: 0.3862604\n",
      "\tspeed: 0.1399s/iter; left time: 4910.4735s\n",
      "\titers: 3300, epoch: 1 | loss: 0.4146830\n",
      "\tspeed: 0.1399s/iter; left time: 4895.9985s\n",
      "\titers: 3400, epoch: 1 | loss: 0.5658230\n",
      "\tspeed: 0.1399s/iter; left time: 4883.3171s\n",
      "\titers: 3500, epoch: 1 | loss: 0.5473310\n",
      "\tspeed: 0.1399s/iter; left time: 4867.9135s\n",
      "\titers: 3600, epoch: 1 | loss: 0.5609989\n",
      "\tspeed: 0.1400s/iter; left time: 4859.4030s\n",
      "\titers: 3700, epoch: 1 | loss: 0.6438851\n",
      "\tspeed: 0.1402s/iter; left time: 4850.5508s\n",
      "\titers: 3800, epoch: 1 | loss: 0.3701969\n",
      "\tspeed: 0.1404s/iter; left time: 4843.4835s\n",
      "Epoch: 1 cost time: 546.7315905094147\n",
      "Epoch: 1, Steps: 3830 | Train Loss: 0.5578935 Vali Loss: 3.3997271 Test Loss: 1.6059846\n",
      "Validation loss decreased (inf --> 3.399727).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.8432055\n",
      "\tspeed: 1.4127s/iter; left time: 48556.3539s\n",
      "\titers: 200, epoch: 2 | loss: 0.6546659\n",
      "\tspeed: 0.1397s/iter; left time: 4789.3041s\n",
      "\titers: 300, epoch: 2 | loss: 0.5784999\n",
      "\tspeed: 0.1397s/iter; left time: 4772.6447s\n",
      "\titers: 400, epoch: 2 | loss: 0.3865299\n",
      "\tspeed: 0.1399s/iter; left time: 4765.4518s\n",
      "\titers: 500, epoch: 2 | loss: 0.4473351\n",
      "\tspeed: 0.1400s/iter; left time: 4756.5220s\n",
      "\titers: 600, epoch: 2 | loss: 0.4132476\n",
      "\tspeed: 0.1400s/iter; left time: 4742.4924s\n",
      "\titers: 700, epoch: 2 | loss: 0.5923891\n",
      "\tspeed: 0.1399s/iter; left time: 4725.2636s\n",
      "\titers: 800, epoch: 2 | loss: 0.4439422\n",
      "\tspeed: 0.1400s/iter; left time: 4713.6347s\n",
      "\titers: 900, epoch: 2 | loss: 0.3585991\n",
      "\tspeed: 0.1399s/iter; left time: 4695.1303s\n",
      "\titers: 1000, epoch: 2 | loss: 0.7382043\n",
      "\tspeed: 0.1404s/iter; left time: 4700.6309s\n",
      "\titers: 1100, epoch: 2 | loss: 0.5146695\n",
      "\tspeed: 0.1403s/iter; left time: 4683.5291s\n",
      "\titers: 1200, epoch: 2 | loss: 0.9761815\n",
      "\tspeed: 0.1398s/iter; left time: 4650.5154s\n",
      "\titers: 1300, epoch: 2 | loss: 0.4105241\n",
      "\tspeed: 0.1399s/iter; left time: 4639.8748s\n",
      "\titers: 1400, epoch: 2 | loss: 0.5892549\n",
      "\tspeed: 0.1401s/iter; left time: 4633.0605s\n",
      "\titers: 1500, epoch: 2 | loss: 0.5695882\n",
      "\tspeed: 0.1400s/iter; left time: 4615.4742s\n",
      "\titers: 1600, epoch: 2 | loss: 0.3716564\n",
      "\tspeed: 0.1401s/iter; left time: 4605.9569s\n",
      "\titers: 1700, epoch: 2 | loss: 0.3752961\n",
      "\tspeed: 0.1399s/iter; left time: 4584.8862s\n",
      "\titers: 1800, epoch: 2 | loss: 0.3186302\n",
      "\tspeed: 0.1400s/iter; left time: 4572.5918s\n",
      "\titers: 1900, epoch: 2 | loss: 0.6832559\n",
      "\tspeed: 0.1399s/iter; left time: 4555.9213s\n",
      "\titers: 2000, epoch: 2 | loss: 0.4649288\n",
      "\tspeed: 0.1400s/iter; left time: 4546.7850s\n",
      "\titers: 2100, epoch: 2 | loss: 0.5061871\n",
      "\tspeed: 0.1404s/iter; left time: 4543.3919s\n",
      "\titers: 2200, epoch: 2 | loss: 0.3353967\n",
      "\tspeed: 0.1405s/iter; left time: 4532.6793s\n",
      "\titers: 2300, epoch: 2 | loss: 0.4303335\n",
      "\tspeed: 0.1398s/iter; left time: 4498.9496s\n",
      "\titers: 2400, epoch: 2 | loss: 0.3195690\n",
      "\tspeed: 0.1398s/iter; left time: 4484.3536s\n",
      "\titers: 2500, epoch: 2 | loss: 0.2678990\n",
      "\tspeed: 0.1399s/iter; left time: 4474.0453s\n",
      "\titers: 2600, epoch: 2 | loss: 0.3968546\n",
      "\tspeed: 0.1398s/iter; left time: 4456.9849s\n",
      "\titers: 2700, epoch: 2 | loss: 0.3994270\n",
      "\tspeed: 0.1399s/iter; left time: 4446.1167s\n",
      "\titers: 2800, epoch: 2 | loss: 0.4593655\n",
      "\tspeed: 0.1402s/iter; left time: 4439.5331s\n",
      "\titers: 2900, epoch: 2 | loss: 0.3041640\n",
      "\tspeed: 0.1403s/iter; left time: 4429.5268s\n",
      "\titers: 3000, epoch: 2 | loss: 0.3057697\n",
      "\tspeed: 0.1400s/iter; left time: 4407.3638s\n",
      "\titers: 3100, epoch: 2 | loss: 0.5339546\n",
      "\tspeed: 0.1403s/iter; left time: 4401.3689s\n",
      "\titers: 3200, epoch: 2 | loss: 0.3625777\n",
      "\tspeed: 0.1400s/iter; left time: 4377.0083s\n",
      "\titers: 3300, epoch: 2 | loss: 0.2889528\n",
      "\tspeed: 0.1400s/iter; left time: 4363.7370s\n",
      "\titers: 3400, epoch: 2 | loss: 0.3935319\n",
      "\tspeed: 0.1401s/iter; left time: 4353.0027s\n",
      "\titers: 3500, epoch: 2 | loss: 0.3198628\n",
      "\tspeed: 0.1398s/iter; left time: 4330.0287s\n",
      "\titers: 3600, epoch: 2 | loss: 0.3684818\n",
      "\tspeed: 0.1406s/iter; left time: 4339.1024s\n",
      "\titers: 3700, epoch: 2 | loss: 0.4739920\n",
      "\tspeed: 0.1405s/iter; left time: 4322.5985s\n",
      "\titers: 3800, epoch: 2 | loss: 0.3241272\n",
      "\tspeed: 0.1397s/iter; left time: 4286.1726s\n",
      "Epoch: 2 cost time: 536.8567225933075\n",
      "Epoch: 2, Steps: 3830 | Train Loss: 0.4234392 Vali Loss: 3.3529301 Test Loss: 1.6461641\n",
      "Validation loss decreased (3.399727 --> 3.352930).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3031180\n",
      "\tspeed: 1.4256s/iter; left time: 43538.2068s\n",
      "\titers: 200, epoch: 3 | loss: 0.2648374\n",
      "\tspeed: 0.1399s/iter; left time: 4258.2504s\n",
      "\titers: 300, epoch: 3 | loss: 0.4055599\n",
      "\tspeed: 0.1399s/iter; left time: 4244.4266s\n",
      "\titers: 400, epoch: 3 | loss: 0.4229195\n",
      "\tspeed: 0.1399s/iter; left time: 4229.2247s\n",
      "\titers: 500, epoch: 3 | loss: 0.3220488\n",
      "\tspeed: 0.1398s/iter; left time: 4213.9594s\n",
      "\titers: 600, epoch: 3 | loss: 0.3271764\n",
      "\tspeed: 0.1402s/iter; left time: 4211.9274s\n",
      "\titers: 700, epoch: 3 | loss: 0.3978080\n",
      "\tspeed: 0.1400s/iter; left time: 4192.2756s\n",
      "\titers: 800, epoch: 3 | loss: 0.3760782\n",
      "\tspeed: 0.1398s/iter; left time: 4171.7072s\n",
      "\titers: 900, epoch: 3 | loss: 0.2779164\n",
      "\tspeed: 0.1404s/iter; left time: 4177.0441s\n",
      "\titers: 1000, epoch: 3 | loss: 0.2727501\n",
      "\tspeed: 0.1404s/iter; left time: 4160.6791s\n",
      "\titers: 1100, epoch: 3 | loss: 0.2552420\n",
      "\tspeed: 0.1399s/iter; left time: 4133.8753s\n",
      "\titers: 1200, epoch: 3 | loss: 0.2619073\n",
      "\tspeed: 0.1405s/iter; left time: 4136.8107s\n",
      "\titers: 1300, epoch: 3 | loss: 0.3671553\n",
      "\tspeed: 0.1400s/iter; left time: 4108.0333s\n",
      "\titers: 1400, epoch: 3 | loss: 0.2771694\n",
      "\tspeed: 0.1404s/iter; left time: 4106.1149s\n",
      "\titers: 1500, epoch: 3 | loss: 0.2456159\n",
      "\tspeed: 0.1404s/iter; left time: 4091.4129s\n",
      "\titers: 1600, epoch: 3 | loss: 0.3419618\n",
      "\tspeed: 0.1399s/iter; left time: 4064.0045s\n",
      "\titers: 1700, epoch: 3 | loss: 0.3727803\n",
      "\tspeed: 0.1398s/iter; left time: 4047.0328s\n",
      "\titers: 1800, epoch: 3 | loss: 0.3076602\n",
      "\tspeed: 0.1399s/iter; left time: 4035.5384s\n",
      "\titers: 1900, epoch: 3 | loss: 0.3135683\n",
      "\tspeed: 0.1399s/iter; left time: 4021.6976s\n",
      "\titers: 2000, epoch: 3 | loss: 0.3695889\n",
      "\tspeed: 0.1399s/iter; left time: 4006.9622s\n",
      "\titers: 2100, epoch: 3 | loss: 0.4371886\n",
      "\tspeed: 0.1400s/iter; left time: 3994.7383s\n",
      "\titers: 2200, epoch: 3 | loss: 0.3691134\n",
      "\tspeed: 0.1404s/iter; left time: 3994.2132s\n",
      "\titers: 2300, epoch: 3 | loss: 0.2734621\n",
      "\tspeed: 0.1402s/iter; left time: 3972.0528s\n",
      "\titers: 2400, epoch: 3 | loss: 0.3388910\n",
      "\tspeed: 0.1399s/iter; left time: 3950.5047s\n",
      "\titers: 2500, epoch: 3 | loss: 0.2919981\n",
      "\tspeed: 0.1399s/iter; left time: 3935.7222s\n",
      "\titers: 2600, epoch: 3 | loss: 0.3620425\n",
      "\tspeed: 0.1399s/iter; left time: 3923.7190s\n",
      "\titers: 2700, epoch: 3 | loss: 0.4162052\n",
      "\tspeed: 0.1400s/iter; left time: 3910.3597s\n",
      "\titers: 2800, epoch: 3 | loss: 0.3216344\n",
      "\tspeed: 0.1401s/iter; left time: 3899.8146s\n",
      "\titers: 2900, epoch: 3 | loss: 0.2423697\n",
      "\tspeed: 0.1399s/iter; left time: 3879.7332s\n",
      "\titers: 3000, epoch: 3 | loss: 0.2878691\n",
      "\tspeed: 0.1405s/iter; left time: 3882.8280s\n",
      "\titers: 3100, epoch: 3 | loss: 0.2743664\n",
      "\tspeed: 0.1400s/iter; left time: 3854.6335s\n",
      "\titers: 3200, epoch: 3 | loss: 0.3879099\n",
      "\tspeed: 0.1399s/iter; left time: 3838.2316s\n",
      "\titers: 3300, epoch: 3 | loss: 0.4077245\n",
      "\tspeed: 0.1400s/iter; left time: 3828.4432s\n",
      "\titers: 3400, epoch: 3 | loss: 0.2156564\n",
      "\tspeed: 0.1405s/iter; left time: 3826.4230s\n",
      "\titers: 3500, epoch: 3 | loss: 0.2819181\n",
      "\tspeed: 0.1400s/iter; left time: 3799.3545s\n",
      "\titers: 3600, epoch: 3 | loss: 0.3304936\n",
      "\tspeed: 0.1402s/iter; left time: 3792.2118s\n",
      "\titers: 3700, epoch: 3 | loss: 0.3183645\n",
      "\tspeed: 0.1399s/iter; left time: 3768.2820s\n",
      "\titers: 3800, epoch: 3 | loss: 0.2706727\n",
      "\tspeed: 0.1399s/iter; left time: 3755.6698s\n",
      "Epoch: 3 cost time: 537.0267972946167\n",
      "Epoch: 3, Steps: 3830 | Train Loss: 0.3386722 Vali Loss: 3.3932397 Test Loss: 1.6629480\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2276661\n",
      "\tspeed: 1.3997s/iter; left time: 37388.0495s\n",
      "\titers: 200, epoch: 4 | loss: 0.4205934\n",
      "\tspeed: 0.1401s/iter; left time: 3727.7777s\n",
      "\titers: 300, epoch: 4 | loss: 0.2796493\n",
      "\tspeed: 0.1401s/iter; left time: 3714.0407s\n",
      "\titers: 400, epoch: 4 | loss: 0.3082888\n",
      "\tspeed: 0.1400s/iter; left time: 3697.7380s\n",
      "\titers: 500, epoch: 4 | loss: 0.3720171\n",
      "\tspeed: 0.1402s/iter; left time: 3688.3806s\n",
      "\titers: 600, epoch: 4 | loss: 0.2028419\n",
      "\tspeed: 0.1402s/iter; left time: 3675.4799s\n",
      "\titers: 700, epoch: 4 | loss: 0.3387893\n",
      "\tspeed: 0.1403s/iter; left time: 3662.4349s\n",
      "\titers: 800, epoch: 4 | loss: 0.3856590\n",
      "\tspeed: 0.1402s/iter; left time: 3645.6272s\n",
      "\titers: 900, epoch: 4 | loss: 0.2495219\n",
      "\tspeed: 0.1400s/iter; left time: 3626.5700s\n",
      "\titers: 1000, epoch: 4 | loss: 0.3078038\n",
      "\tspeed: 0.1400s/iter; left time: 3612.2854s\n",
      "\titers: 1100, epoch: 4 | loss: 0.2108934\n",
      "\tspeed: 0.1398s/iter; left time: 3594.6351s\n",
      "\titers: 1200, epoch: 4 | loss: 0.2746490\n",
      "\tspeed: 0.1403s/iter; left time: 3592.0629s\n",
      "\titers: 1300, epoch: 4 | loss: 0.4011002\n",
      "\tspeed: 0.1399s/iter; left time: 3568.1713s\n",
      "\titers: 1400, epoch: 4 | loss: 0.2661648\n",
      "\tspeed: 0.1400s/iter; left time: 3556.3828s\n",
      "\titers: 1500, epoch: 4 | loss: 0.3251716\n",
      "\tspeed: 0.1399s/iter; left time: 3540.0505s\n",
      "\titers: 1600, epoch: 4 | loss: 0.3681841\n",
      "\tspeed: 0.1398s/iter; left time: 3525.7266s\n",
      "\titers: 1700, epoch: 4 | loss: 0.2985007\n",
      "\tspeed: 0.1401s/iter; left time: 3518.6946s\n",
      "\titers: 1800, epoch: 4 | loss: 0.2744301\n",
      "\tspeed: 0.1402s/iter; left time: 3506.2620s\n",
      "\titers: 1900, epoch: 4 | loss: 0.3994609\n",
      "\tspeed: 0.1399s/iter; left time: 3484.5253s\n",
      "\titers: 2000, epoch: 4 | loss: 0.3910164\n",
      "\tspeed: 0.1398s/iter; left time: 3468.3142s\n",
      "\titers: 2100, epoch: 4 | loss: 0.2104092\n",
      "\tspeed: 0.1404s/iter; left time: 3468.6416s\n",
      "\titers: 2200, epoch: 4 | loss: 0.3616436\n",
      "\tspeed: 0.1401s/iter; left time: 3448.0730s\n",
      "\titers: 2300, epoch: 4 | loss: 0.2228075\n",
      "\tspeed: 0.1399s/iter; left time: 3428.6571s\n",
      "\titers: 2400, epoch: 4 | loss: 0.4990823\n",
      "\tspeed: 0.1401s/iter; left time: 3418.9888s\n",
      "\titers: 2500, epoch: 4 | loss: 0.2133156\n",
      "\tspeed: 0.1400s/iter; left time: 3402.3434s\n",
      "\titers: 2600, epoch: 4 | loss: 0.2367507\n",
      "\tspeed: 0.1398s/iter; left time: 3384.0312s\n",
      "\titers: 2700, epoch: 4 | loss: 0.2394204\n",
      "\tspeed: 0.1401s/iter; left time: 3377.9008s\n",
      "\titers: 2800, epoch: 4 | loss: 0.2815419\n",
      "\tspeed: 0.1399s/iter; left time: 3359.2603s\n",
      "\titers: 2900, epoch: 4 | loss: 0.2732027\n",
      "\tspeed: 0.1401s/iter; left time: 3348.7435s\n",
      "\titers: 3000, epoch: 4 | loss: 0.2074657\n",
      "\tspeed: 0.1397s/iter; left time: 3327.1261s\n",
      "\titers: 3100, epoch: 4 | loss: 0.2296546\n",
      "\tspeed: 0.1397s/iter; left time: 3313.0447s\n",
      "\titers: 3200, epoch: 4 | loss: 0.4339831\n",
      "\tspeed: 0.1399s/iter; left time: 3302.4353s\n",
      "\titers: 3300, epoch: 4 | loss: 0.2441240\n",
      "\tspeed: 0.1400s/iter; left time: 3290.5265s\n",
      "\titers: 3400, epoch: 4 | loss: 0.3106340\n",
      "\tspeed: 0.1398s/iter; left time: 3273.1045s\n",
      "\titers: 3500, epoch: 4 | loss: 0.2654446\n",
      "\tspeed: 0.1401s/iter; left time: 3266.0761s\n",
      "\titers: 3600, epoch: 4 | loss: 0.3563465\n",
      "\tspeed: 0.1398s/iter; left time: 3244.8726s\n",
      "\titers: 3700, epoch: 4 | loss: 0.3072009\n",
      "\tspeed: 0.1400s/iter; left time: 3234.8858s\n",
      "\titers: 3800, epoch: 4 | loss: 0.3165165\n",
      "\tspeed: 0.1399s/iter; left time: 3219.0118s\n",
      "Epoch: 4 cost time: 536.8765614032745\n",
      "Epoch: 4, Steps: 3830 | Train Loss: 0.3029121 Vali Loss: 3.3849776 Test Loss: 1.6639204\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2441343\n",
      "\tspeed: 1.4206s/iter; left time: 32505.6657s\n",
      "\titers: 200, epoch: 5 | loss: 0.2541766\n",
      "\tspeed: 0.1397s/iter; left time: 3182.4947s\n",
      "\titers: 300, epoch: 5 | loss: 0.2129252\n",
      "\tspeed: 0.1399s/iter; left time: 3172.7306s\n",
      "\titers: 400, epoch: 5 | loss: 0.3316916\n",
      "\tspeed: 0.1399s/iter; left time: 3159.8922s\n",
      "\titers: 500, epoch: 5 | loss: 0.5237550\n",
      "\tspeed: 0.1399s/iter; left time: 3144.4859s\n",
      "\titers: 600, epoch: 5 | loss: 0.2715912\n",
      "\tspeed: 0.1402s/iter; left time: 3137.5080s\n",
      "\titers: 700, epoch: 5 | loss: 0.3012120\n",
      "\tspeed: 0.1398s/iter; left time: 3115.6159s\n",
      "\titers: 800, epoch: 5 | loss: 0.3105869\n",
      "\tspeed: 0.1398s/iter; left time: 3101.7114s\n",
      "\titers: 900, epoch: 5 | loss: 0.2900448\n",
      "\tspeed: 0.1400s/iter; left time: 3090.4837s\n",
      "\titers: 1000, epoch: 5 | loss: 0.2699829\n",
      "\tspeed: 0.1399s/iter; left time: 3074.6247s\n",
      "\titers: 1100, epoch: 5 | loss: 0.2807636\n",
      "\tspeed: 0.1404s/iter; left time: 3072.3235s\n",
      "\titers: 1200, epoch: 5 | loss: 0.3673612\n",
      "\tspeed: 0.1400s/iter; left time: 3048.6842s\n",
      "\titers: 1300, epoch: 5 | loss: 0.2459273\n",
      "\tspeed: 0.1399s/iter; left time: 3032.7179s\n",
      "\titers: 1400, epoch: 5 | loss: 0.2326990\n",
      "\tspeed: 0.1398s/iter; left time: 3016.8887s\n",
      "\titers: 1500, epoch: 5 | loss: 0.3481472\n",
      "\tspeed: 0.1399s/iter; left time: 3004.5385s\n",
      "\titers: 1600, epoch: 5 | loss: 0.2814051\n",
      "\tspeed: 0.1404s/iter; left time: 3002.1759s\n",
      "\titers: 1700, epoch: 5 | loss: 0.3632475\n",
      "\tspeed: 0.1403s/iter; left time: 2984.8571s\n",
      "\titers: 1800, epoch: 5 | loss: 0.2075426\n",
      "\tspeed: 0.1401s/iter; left time: 2966.7902s\n",
      "\titers: 1900, epoch: 5 | loss: 0.2045826\n",
      "\tspeed: 0.1399s/iter; left time: 2948.8113s\n",
      "\titers: 2000, epoch: 5 | loss: 0.2732796\n",
      "\tspeed: 0.1401s/iter; left time: 2939.4846s\n",
      "\titers: 2100, epoch: 5 | loss: 0.3450975\n",
      "\tspeed: 0.1402s/iter; left time: 2926.7531s\n",
      "\titers: 2200, epoch: 5 | loss: 0.3334667\n",
      "\tspeed: 0.1399s/iter; left time: 2907.6522s\n",
      "\titers: 2300, epoch: 5 | loss: 0.3089196\n",
      "\tspeed: 0.1400s/iter; left time: 2894.4464s\n",
      "\titers: 2400, epoch: 5 | loss: 0.2265164\n",
      "\tspeed: 0.1402s/iter; left time: 2885.8208s\n",
      "\titers: 2500, epoch: 5 | loss: 0.3921247\n",
      "\tspeed: 0.1400s/iter; left time: 2866.9014s\n",
      "\titers: 2600, epoch: 5 | loss: 0.2300909\n",
      "\tspeed: 0.1400s/iter; left time: 2853.7833s\n",
      "\titers: 2700, epoch: 5 | loss: 0.2136138\n",
      "\tspeed: 0.1404s/iter; left time: 2848.3607s\n",
      "\titers: 2800, epoch: 5 | loss: 0.3690777\n",
      "\tspeed: 0.1400s/iter; left time: 2825.9671s\n",
      "\titers: 2900, epoch: 5 | loss: 0.2989986\n",
      "\tspeed: 0.1404s/iter; left time: 2819.7252s\n",
      "\titers: 3000, epoch: 5 | loss: 0.2541467\n",
      "\tspeed: 0.1401s/iter; left time: 2799.4769s\n",
      "\titers: 3100, epoch: 5 | loss: 0.2895015\n",
      "\tspeed: 0.1404s/iter; left time: 2790.6065s\n",
      "\titers: 3200, epoch: 5 | loss: 0.3156612\n",
      "\tspeed: 0.1399s/iter; left time: 2768.2017s\n",
      "\titers: 3300, epoch: 5 | loss: 0.3598620\n",
      "\tspeed: 0.1405s/iter; left time: 2764.9270s\n",
      "\titers: 3400, epoch: 5 | loss: 0.2825662\n",
      "\tspeed: 0.1404s/iter; left time: 2750.0741s\n",
      "\titers: 3500, epoch: 5 | loss: 0.2221274\n",
      "\tspeed: 0.1405s/iter; left time: 2736.3341s\n",
      "\titers: 3600, epoch: 5 | loss: 0.3370174\n",
      "\tspeed: 0.1404s/iter; left time: 2721.4207s\n",
      "\titers: 3700, epoch: 5 | loss: 0.2449008\n",
      "\tspeed: 0.1399s/iter; left time: 2697.2445s\n",
      "\titers: 3800, epoch: 5 | loss: 0.3446505\n",
      "\tspeed: 0.1402s/iter; left time: 2689.1100s\n",
      "Epoch: 5 cost time: 537.2477781772614\n",
      "Epoch: 5, Steps: 3830 | Train Loss: 0.2853567 Vali Loss: 3.3899088 Test Loss: 1.6625836\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : weather_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 34983\n",
      "test shape: (34983, 96, 31) (34983, 96, 31)\n",
      "test shape: (34983, 96, 31) (34983, 96, 31)\n",
      "mse:1.6466319561004639, mae:0.5500485897064209\n"
     ]
    }
   ],
   "source": [
    "# predict\n",
    "!bash ./scripts/Weather_script/myAutoformer.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80cc94d9-f6fd-46c3-90a9-c6c612260808",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ScriptMethodStub' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# print(model)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m traced_model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_x_mark\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec_inp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_y_mark\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(traced_model)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# traced_model.save(\"tracedModel.pt\")\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m#                   input_names = ['input'],   # the model's input names\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m#                   output_names = ['output'])\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/jit/_trace.py:750\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m--> 750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    766\u001b[0m ):\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    768\u001b[0m         func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m,\n\u001b[1;32m    769\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m: example_inputs},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    776\u001b[0m         _module_class,\n\u001b[1;32m    777\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/jit/_trace.py:967\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    963\u001b[0m     argument_names \u001b[38;5;241m=\u001b[39m get_callable_argument_names(func)\n\u001b[1;32m    965\u001b[0m example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[0;32m--> 967\u001b[0m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py:1118\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1118\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ScriptMethodStub' object is not callable"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "batch_x = torch.randn([1, 96, 31]).cpu()\n",
    "batch_x_mark = torch.randn([1, 96, 4]).cpu()\n",
    "dec_inp = torch.randn([1, 144, 31]).cpu()\n",
    "batch_y_mark = torch.randn([1, 144, 4]).cpu()\n",
    "\n",
    "model = torch.load(\"checkpoints/weather_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0/bestModel.pt\").cpu()\n",
    "model.eval()\n",
    "\n",
    "# print(model)\n",
    "traced_model = torch.jit.trace(model,  example_inputs=(batch_x, batch_x_mark, dec_inp, batch_y_mark))\n",
    "print(traced_model)\n",
    "# traced_model.save(\"tracedModel.pt\")\n",
    "\n",
    "\n",
    "# torch.onnx.export(traced_model,               # model being run\n",
    "#                   (batch_x, batch_x_mark, dec_inp, batch_y_mark),                         # model input (or a tuple for multiple inputs)\n",
    "#                   \"model.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "#                   export_params=True,        # store the trained parameter weights inside the model file\n",
    "#                   cj          # the ONNX version to export the model to\n",
    "#                   do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "#                   input_names = ['input'],   # the model's input names\n",
    "#                   output_names = ['output'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df87c0e9-db92-4b81-9853-ea642ff42d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 31])\n"
     ]
    }
   ],
   "source": [
    "output = traced_model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "print(output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b46632-5edc-422a-9b4e-ebf851961f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/notebooks/Autoformer-main\n",
      "Args in experiment:\n",
      "Namespace(activation='gelu', batch_size=32, bucket_size=4, c_out=31, checkpoints='./checkpoints/', d_ff=2048, d_layers=1, d_model=512, data='custom', data_path='data.csv', dec_in=31, des='Exp', devices='0,1,2', distil=True, do_predict=True, dropout=0.05, e_layers=2, embed='timeF', enc_in=31, factor=3, features='M', freq='m', gpu=0, is_training=1, itr=1, label_len=48, learning_rate=0.0001, loss='mse', lradj='type1', model='Autoformer', model_id='weather_96_96', moving_avg=25, n_hashes=4, n_heads=8, num_workers=10, output_attention=False, patience=3, pred_len=96, root_path='./dataset/weather/', seq_len=96, target='temp', train_epochs=10, use_amp=False, use_gpu=True, use_multi_gpu=False)\n",
      "-------\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : weather_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 122583\n",
      "val 17445\n",
      "test 34983\n",
      "\titers: 100, epoch: 1 | loss: 0.5649285\n",
      "\tspeed: 0.2463s/iter; left time: 9409.4098s\n",
      "\titers: 200, epoch: 1 | loss: 0.6416266\n",
      "\tspeed: 0.1397s/iter; left time: 5321.7430s\n",
      "\titers: 300, epoch: 1 | loss: 0.7386528\n",
      "\tspeed: 0.1397s/iter; left time: 5307.9619s\n",
      "\titers: 400, epoch: 1 | loss: 0.7040796\n",
      "\tspeed: 0.1402s/iter; left time: 5315.4907s\n",
      "\titers: 500, epoch: 1 | loss: 0.7585597\n",
      "\tspeed: 0.1404s/iter; left time: 5305.7469s\n",
      "\titers: 600, epoch: 1 | loss: 0.5162369\n",
      "\tspeed: 0.1396s/iter; left time: 5263.7355s\n",
      "\titers: 700, epoch: 1 | loss: 0.5217395\n",
      "\tspeed: 0.1396s/iter; left time: 5248.1380s\n",
      "\titers: 800, epoch: 1 | loss: 0.4592277\n",
      "\tspeed: 0.1398s/iter; left time: 5243.2074s\n",
      "\titers: 900, epoch: 1 | loss: 0.5449053\n",
      "\tspeed: 0.1399s/iter; left time: 5232.2684s\n",
      "\titers: 1000, epoch: 1 | loss: 0.5209422\n",
      "\tspeed: 0.1397s/iter; left time: 5211.6482s\n",
      "\titers: 1100, epoch: 1 | loss: 0.5349638\n",
      "\tspeed: 0.1396s/iter; left time: 5193.7810s\n",
      "\titers: 1200, epoch: 1 | loss: 0.7311170\n",
      "\tspeed: 0.1398s/iter; left time: 5188.0808s\n",
      "\titers: 1300, epoch: 1 | loss: 0.4511763\n",
      "\tspeed: 0.1396s/iter; left time: 5165.1053s\n",
      "\titers: 1400, epoch: 1 | loss: 0.6265048\n",
      "\tspeed: 0.1399s/iter; left time: 5161.3204s\n",
      "\titers: 1500, epoch: 1 | loss: 0.4494259\n",
      "\tspeed: 0.1397s/iter; left time: 5142.3507s\n",
      "\titers: 1600, epoch: 1 | loss: 0.4875981\n",
      "\tspeed: 0.1397s/iter; left time: 5128.2418s\n",
      "\titers: 1700, epoch: 1 | loss: 0.4453555\n",
      "\tspeed: 0.1397s/iter; left time: 5112.2478s\n",
      "\titers: 1800, epoch: 1 | loss: 0.5467491\n",
      "\tspeed: 0.1394s/iter; left time: 5088.9684s\n",
      "\titers: 1900, epoch: 1 | loss: 0.6109719\n",
      "\tspeed: 0.1396s/iter; left time: 5081.2825s\n",
      "\titers: 2000, epoch: 1 | loss: 0.4626119\n",
      "\tspeed: 0.1397s/iter; left time: 5070.3290s\n",
      "\titers: 2100, epoch: 1 | loss: 0.6962865\n",
      "\tspeed: 0.1397s/iter; left time: 5056.2373s\n",
      "\titers: 2200, epoch: 1 | loss: 0.4841798\n",
      "\tspeed: 0.1396s/iter; left time: 5041.4100s\n",
      "\titers: 2300, epoch: 1 | loss: 0.5480644\n",
      "\tspeed: 0.1396s/iter; left time: 5026.1028s\n",
      "\titers: 2400, epoch: 1 | loss: 0.8538902\n",
      "\tspeed: 0.1396s/iter; left time: 5010.3579s\n",
      "\titers: 2500, epoch: 1 | loss: 0.7693002\n",
      "\tspeed: 0.1394s/iter; left time: 4991.9113s\n",
      "\titers: 2600, epoch: 1 | loss: 0.4123374\n",
      "\tspeed: 0.1396s/iter; left time: 4983.2345s\n",
      "\titers: 2700, epoch: 1 | loss: 0.5815517\n",
      "\tspeed: 0.1396s/iter; left time: 4969.6607s\n",
      "\titers: 2800, epoch: 1 | loss: 0.5587901\n",
      "\tspeed: 0.1400s/iter; left time: 4971.1133s\n",
      "\titers: 2900, epoch: 1 | loss: 0.4308668\n",
      "\tspeed: 0.1401s/iter; left time: 4958.9298s\n",
      "\titers: 3000, epoch: 1 | loss: 0.6069193\n",
      "\tspeed: 0.1398s/iter; left time: 4934.7327s\n",
      "\titers: 3100, epoch: 1 | loss: 0.4966746\n",
      "\tspeed: 0.1397s/iter; left time: 4918.5207s\n",
      "\titers: 3200, epoch: 1 | loss: 0.4818163\n",
      "\tspeed: 0.1399s/iter; left time: 4910.1608s\n",
      "\titers: 3300, epoch: 1 | loss: 0.5453822\n",
      "\tspeed: 0.1395s/iter; left time: 4883.6311s\n",
      "\titers: 3400, epoch: 1 | loss: 0.4217989\n",
      "\tspeed: 0.1395s/iter; left time: 4869.8573s\n",
      "\titers: 3500, epoch: 1 | loss: 0.4164906\n",
      "\tspeed: 0.1395s/iter; left time: 4855.3004s\n",
      "\titers: 3600, epoch: 1 | loss: 0.6271695\n",
      "\tspeed: 0.1395s/iter; left time: 4839.2513s\n",
      "\titers: 3700, epoch: 1 | loss: 0.5121295\n",
      "\tspeed: 0.1396s/iter; left time: 4830.6595s\n",
      "\titers: 3800, epoch: 1 | loss: 0.3364324\n",
      "\tspeed: 0.1399s/iter; left time: 4827.2344s\n",
      "Epoch: 1 cost time: 545.8675224781036\n",
      "Epoch: 1, Steps: 3830 | Train Loss: 0.5701639 Vali Loss: 3.2791924 Test Loss: 1.5360523\n",
      "Validation loss decreased (inf --> 3.279192).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.6107735\n",
      "\tspeed: 1.4270s/iter; left time: 49046.4672s\n",
      "\titers: 200, epoch: 2 | loss: 0.3471129\n",
      "\tspeed: 0.1397s/iter; left time: 4787.1177s\n",
      "\titers: 300, epoch: 2 | loss: 0.4664775\n",
      "\tspeed: 0.1396s/iter; left time: 4768.7661s\n",
      "\titers: 400, epoch: 2 | loss: 0.4747135\n",
      "\tspeed: 0.1396s/iter; left time: 4755.3811s\n",
      "\titers: 500, epoch: 2 | loss: 0.4892007\n",
      "\tspeed: 0.1396s/iter; left time: 4742.6301s\n",
      "\titers: 600, epoch: 2 | loss: 0.4780861\n",
      "\tspeed: 0.1396s/iter; left time: 4728.8423s\n",
      "\titers: 700, epoch: 2 | loss: 0.3995554\n",
      "\tspeed: 0.1396s/iter; left time: 4715.9126s\n",
      "\titers: 800, epoch: 2 | loss: 0.3138148\n",
      "\tspeed: 0.1399s/iter; left time: 4710.3724s\n",
      "\titers: 900, epoch: 2 | loss: 0.5451141\n",
      "\tspeed: 0.1396s/iter; left time: 4686.5723s\n",
      "\titers: 1000, epoch: 2 | loss: 0.4240740\n",
      "\tspeed: 0.1399s/iter; left time: 4683.4071s\n",
      "\titers: 1100, epoch: 2 | loss: 0.3633409\n",
      "\tspeed: 0.1400s/iter; left time: 4671.4118s\n",
      "\titers: 1200, epoch: 2 | loss: 0.4588864\n",
      "\tspeed: 0.1396s/iter; left time: 4646.1117s\n",
      "\titers: 1300, epoch: 2 | loss: 0.5083885\n",
      "\tspeed: 0.1396s/iter; left time: 4631.9602s\n",
      "\titers: 1400, epoch: 2 | loss: 0.4796209\n",
      "\tspeed: 0.1398s/iter; left time: 4621.6855s\n",
      "\titers: 1500, epoch: 2 | loss: 0.7448916\n",
      "\tspeed: 0.1396s/iter; left time: 4603.6169s\n",
      "\titers: 1600, epoch: 2 | loss: 0.3302622\n",
      "\tspeed: 0.1396s/iter; left time: 4587.1550s\n",
      "\titers: 1700, epoch: 2 | loss: 0.3908187\n",
      "\tspeed: 0.1396s/iter; left time: 4573.6863s\n",
      "\titers: 1800, epoch: 2 | loss: 0.4984723\n",
      "\tspeed: 0.1397s/iter; left time: 4564.6650s\n",
      "\titers: 1900, epoch: 2 | loss: 0.3636867\n",
      "\tspeed: 0.1401s/iter; left time: 4562.1917s\n",
      "\titers: 2000, epoch: 2 | loss: 0.4052393\n",
      "\tspeed: 0.1398s/iter; left time: 4538.4430s\n",
      "\titers: 2100, epoch: 2 | loss: 0.4077164\n",
      "\tspeed: 0.1397s/iter; left time: 4522.2281s\n",
      "\titers: 2200, epoch: 2 | loss: 0.5644093\n",
      "\tspeed: 0.1396s/iter; left time: 4506.1422s\n",
      "\titers: 2300, epoch: 2 | loss: 0.4482222\n",
      "\tspeed: 0.1396s/iter; left time: 4490.1638s\n",
      "\titers: 2400, epoch: 2 | loss: 0.5436557\n",
      "\tspeed: 0.1395s/iter; left time: 4475.3979s\n",
      "\titers: 2500, epoch: 2 | loss: 0.3396111\n",
      "\tspeed: 0.1395s/iter; left time: 4461.3264s\n",
      "\titers: 2600, epoch: 2 | loss: 0.3931322\n",
      "\tspeed: 0.1395s/iter; left time: 4446.1579s\n",
      "\titers: 2700, epoch: 2 | loss: 0.4018729\n",
      "\tspeed: 0.1395s/iter; left time: 4431.6121s\n",
      "\titers: 2800, epoch: 2 | loss: 0.3652090\n",
      "\tspeed: 0.1395s/iter; left time: 4418.5623s\n",
      "\titers: 2900, epoch: 2 | loss: 0.2962732\n",
      "\tspeed: 0.1396s/iter; left time: 4407.8092s\n",
      "\titers: 3000, epoch: 2 | loss: 0.3920355\n",
      "\tspeed: 0.1401s/iter; left time: 4408.0451s\n",
      "\titers: 3100, epoch: 2 | loss: 0.3884873\n",
      "\tspeed: 0.1396s/iter; left time: 4380.0392s\n",
      "\titers: 3200, epoch: 2 | loss: 0.3101267\n",
      "\tspeed: 0.1395s/iter; left time: 4363.7695s\n",
      "\titers: 3300, epoch: 2 | loss: 0.5130825\n",
      "\tspeed: 0.1397s/iter; left time: 4355.4583s\n",
      "\titers: 3400, epoch: 2 | loss: 0.4400396\n",
      "\tspeed: 0.1396s/iter; left time: 4337.4410s\n",
      "\titers: 3500, epoch: 2 | loss: 0.3110731\n",
      "\tspeed: 0.1394s/iter; left time: 4317.8412s\n",
      "\titers: 3600, epoch: 2 | loss: 0.3363622\n",
      "\tspeed: 0.1394s/iter; left time: 4303.3359s\n",
      "\titers: 3700, epoch: 2 | loss: 0.4320040\n",
      "\tspeed: 0.1398s/iter; left time: 4302.1614s\n",
      "\titers: 3800, epoch: 2 | loss: 0.4102987\n",
      "\tspeed: 0.1397s/iter; left time: 4285.3620s\n",
      "Epoch: 2 cost time: 535.6158900260925\n",
      "Epoch: 2, Steps: 3830 | Train Loss: 0.4354229 Vali Loss: 3.3022711 Test Loss: 1.5931196\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3843668\n",
      "\tspeed: 1.3646s/iter; left time: 41675.5920s\n",
      "\titers: 200, epoch: 3 | loss: 0.4115985\n",
      "\tspeed: 0.1398s/iter; left time: 4254.5370s\n",
      "\titers: 300, epoch: 3 | loss: 0.4801918\n",
      "\tspeed: 0.1396s/iter; left time: 4236.4398s\n",
      "\titers: 400, epoch: 3 | loss: 0.4159011\n",
      "\tspeed: 0.1396s/iter; left time: 4222.9971s\n",
      "\titers: 500, epoch: 3 | loss: 0.4125438\n",
      "\tspeed: 0.1395s/iter; left time: 4204.3170s\n",
      "\titers: 600, epoch: 3 | loss: 0.3442772\n",
      "\tspeed: 0.1396s/iter; left time: 4192.3535s\n",
      "\titers: 700, epoch: 3 | loss: 0.4377098\n",
      "\tspeed: 0.1395s/iter; left time: 4176.7529s\n",
      "\titers: 800, epoch: 3 | loss: 0.4040531\n",
      "\tspeed: 0.1395s/iter; left time: 4163.6426s\n",
      "\titers: 900, epoch: 3 | loss: 0.3344379\n",
      "\tspeed: 0.1394s/iter; left time: 4147.1993s\n",
      "\titers: 1000, epoch: 3 | loss: 0.2603115\n",
      "\tspeed: 0.1395s/iter; left time: 4135.4683s\n",
      "\titers: 1100, epoch: 3 | loss: 0.3336005\n",
      "\tspeed: 0.1395s/iter; left time: 4122.0163s\n",
      "\titers: 1200, epoch: 3 | loss: 0.3593930\n",
      "\tspeed: 0.1397s/iter; left time: 4113.1495s\n",
      "\titers: 1300, epoch: 3 | loss: 0.3602786\n",
      "\tspeed: 0.1399s/iter; left time: 4105.7255s\n",
      "\titers: 1400, epoch: 3 | loss: 0.2935415\n",
      "\tspeed: 0.1398s/iter; left time: 4088.3415s\n",
      "\titers: 1500, epoch: 3 | loss: 0.2376135\n",
      "\tspeed: 0.1398s/iter; left time: 4072.5808s\n",
      "\titers: 1600, epoch: 3 | loss: 0.3201842\n",
      "\tspeed: 0.1398s/iter; left time: 4058.6983s\n",
      "\titers: 1700, epoch: 3 | loss: 0.2765294\n",
      "\tspeed: 0.1399s/iter; left time: 4048.9144s\n",
      "\titers: 1800, epoch: 3 | loss: 0.3314952\n",
      "\tspeed: 0.1397s/iter; left time: 4028.2926s\n",
      "\titers: 1900, epoch: 3 | loss: 0.4748977\n",
      "\tspeed: 0.1400s/iter; left time: 4024.5907s\n",
      "\titers: 2000, epoch: 3 | loss: 0.4123508\n",
      "\tspeed: 0.1399s/iter; left time: 4006.9251s\n",
      "\titers: 2100, epoch: 3 | loss: 0.3919356\n",
      "\tspeed: 0.1398s/iter; left time: 3991.0498s\n",
      "\titers: 2200, epoch: 3 | loss: 0.4437461\n",
      "\tspeed: 0.1396s/iter; left time: 3970.7521s\n",
      "\titers: 2300, epoch: 3 | loss: 0.3549105\n",
      "\tspeed: 0.1396s/iter; left time: 3955.3482s\n",
      "\titers: 2400, epoch: 3 | loss: 0.2425498\n",
      "\tspeed: 0.1397s/iter; left time: 3945.3229s\n",
      "\titers: 2500, epoch: 3 | loss: 0.3412719\n",
      "\tspeed: 0.1396s/iter; left time: 3927.8959s\n",
      "\titers: 2600, epoch: 3 | loss: 0.5356094\n",
      "\tspeed: 0.1397s/iter; left time: 3917.4418s\n",
      "\titers: 2700, epoch: 3 | loss: 0.2537449\n",
      "\tspeed: 0.1396s/iter; left time: 3901.0077s\n",
      "\titers: 2800, epoch: 3 | loss: 0.5001757\n",
      "\tspeed: 0.1396s/iter; left time: 3886.3743s\n",
      "\titers: 2900, epoch: 3 | loss: 0.2761581\n",
      "\tspeed: 0.1396s/iter; left time: 3871.3600s\n",
      "\titers: 3000, epoch: 3 | loss: 0.2549932\n",
      "\tspeed: 0.1397s/iter; left time: 3862.0962s\n",
      "\titers: 3100, epoch: 3 | loss: 0.2873867\n",
      "\tspeed: 0.1395s/iter; left time: 3841.5976s\n",
      "\titers: 3200, epoch: 3 | loss: 0.2528276\n",
      "\tspeed: 0.1395s/iter; left time: 3828.8435s\n",
      "\titers: 3300, epoch: 3 | loss: 0.3332483\n",
      "\tspeed: 0.1395s/iter; left time: 3813.4426s\n",
      "\titers: 3400, epoch: 3 | loss: 0.3016890\n",
      "\tspeed: 0.1395s/iter; left time: 3800.5184s\n",
      "\titers: 3500, epoch: 3 | loss: 0.3506525\n",
      "\tspeed: 0.1395s/iter; left time: 3787.5181s\n",
      "\titers: 3600, epoch: 3 | loss: 0.3217185\n",
      "\tspeed: 0.1396s/iter; left time: 3773.6757s\n",
      "\titers: 3700, epoch: 3 | loss: 0.2625308\n",
      "\tspeed: 0.1395s/iter; left time: 3758.8093s\n",
      "\titers: 3800, epoch: 3 | loss: 0.3096915\n",
      "\tspeed: 0.1396s/iter; left time: 3746.8599s\n",
      "Epoch: 3 cost time: 535.6836361885071\n",
      "Epoch: 3, Steps: 3830 | Train Loss: 0.3480911 Vali Loss: 3.3191595 Test Loss: 1.6061552\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3052142\n",
      "\tspeed: 1.3730s/iter; left time: 36673.3112s\n",
      "\titers: 200, epoch: 4 | loss: 0.2932465\n",
      "\tspeed: 0.1396s/iter; left time: 3715.3211s\n",
      "\titers: 300, epoch: 4 | loss: 0.2788377\n",
      "\tspeed: 0.1396s/iter; left time: 3700.2080s\n",
      "\titers: 400, epoch: 4 | loss: 0.3802898\n",
      "\tspeed: 0.1396s/iter; left time: 3688.1523s\n",
      "\titers: 500, epoch: 4 | loss: 0.3355210\n",
      "\tspeed: 0.1395s/iter; left time: 3671.1172s\n",
      "\titers: 600, epoch: 4 | loss: 0.3618732\n",
      "\tspeed: 0.1397s/iter; left time: 3660.4752s\n",
      "\titers: 700, epoch: 4 | loss: 0.2937341\n",
      "\tspeed: 0.1396s/iter; left time: 3645.1157s\n",
      "\titers: 800, epoch: 4 | loss: 0.4589983\n",
      "\tspeed: 0.1396s/iter; left time: 3631.1247s\n",
      "\titers: 900, epoch: 4 | loss: 0.4254611\n",
      "\tspeed: 0.1396s/iter; left time: 3617.1220s\n",
      "\titers: 1000, epoch: 4 | loss: 0.2161672\n",
      "\tspeed: 0.1397s/iter; left time: 3604.5959s\n",
      "\titers: 1100, epoch: 4 | loss: 0.3172085\n",
      "\tspeed: 0.1398s/iter; left time: 3594.0600s\n",
      "\titers: 1200, epoch: 4 | loss: 0.5249767\n",
      "\tspeed: 0.1397s/iter; left time: 3576.7069s\n",
      "\titers: 1300, epoch: 4 | loss: 0.3441451\n",
      "\tspeed: 0.1396s/iter; left time: 3560.9986s\n",
      "\titers: 1400, epoch: 4 | loss: 0.2693469\n",
      "\tspeed: 0.1397s/iter; left time: 3549.2036s\n",
      "\titers: 1500, epoch: 4 | loss: 0.2645313\n",
      "\tspeed: 0.1396s/iter; left time: 3532.5314s\n",
      "\titers: 1600, epoch: 4 | loss: 0.2830330\n",
      "\tspeed: 0.1396s/iter; left time: 3519.6999s\n",
      "\titers: 1700, epoch: 4 | loss: 0.2214662\n",
      "\tspeed: 0.1395s/iter; left time: 3503.3908s\n",
      "\titers: 1800, epoch: 4 | loss: 0.2833739\n",
      "\tspeed: 0.1398s/iter; left time: 3497.4862s\n",
      "\titers: 1900, epoch: 4 | loss: 0.2619366\n",
      "\tspeed: 0.1396s/iter; left time: 3477.4103s\n",
      "\titers: 2000, epoch: 4 | loss: 0.2830086\n",
      "\tspeed: 0.1395s/iter; left time: 3460.6720s\n",
      "\titers: 2100, epoch: 4 | loss: 0.4749389\n",
      "\tspeed: 0.1396s/iter; left time: 3448.8331s\n",
      "\titers: 2200, epoch: 4 | loss: 0.3932276\n",
      "\tspeed: 0.1397s/iter; left time: 3437.3323s\n",
      "\titers: 2300, epoch: 4 | loss: 0.3007528\n",
      "\tspeed: 0.1394s/iter; left time: 3417.7993s\n",
      "\titers: 2400, epoch: 4 | loss: 0.2602288\n",
      "\tspeed: 0.1395s/iter; left time: 3404.3532s\n",
      "\titers: 2500, epoch: 4 | loss: 0.2281078\n",
      "\tspeed: 0.1395s/iter; left time: 3392.0927s\n",
      "\titers: 2600, epoch: 4 | loss: 0.2648363\n",
      "\tspeed: 0.1396s/iter; left time: 3379.3686s\n",
      "\titers: 2700, epoch: 4 | loss: 0.3426941\n",
      "\tspeed: 0.1395s/iter; left time: 3363.5192s\n",
      "\titers: 2800, epoch: 4 | loss: 0.2300017\n",
      "\tspeed: 0.1395s/iter; left time: 3349.3072s\n",
      "\titers: 2900, epoch: 4 | loss: 0.2173640\n",
      "\tspeed: 0.1397s/iter; left time: 3340.9988s\n",
      "\titers: 3000, epoch: 4 | loss: 0.2235580\n",
      "\tspeed: 0.1396s/iter; left time: 3325.0991s\n",
      "\titers: 3100, epoch: 4 | loss: 0.2288048\n",
      "\tspeed: 0.1397s/iter; left time: 3312.1591s\n",
      "\titers: 3200, epoch: 4 | loss: 0.2392535\n",
      "\tspeed: 0.1398s/iter; left time: 3301.4206s\n",
      "\titers: 3300, epoch: 4 | loss: 0.2433739\n",
      "\tspeed: 0.1396s/iter; left time: 3283.0755s\n",
      "\titers: 3400, epoch: 4 | loss: 0.2312580\n",
      "\tspeed: 0.1395s/iter; left time: 3265.0867s\n",
      "\titers: 3500, epoch: 4 | loss: 0.3409073\n",
      "\tspeed: 0.1395s/iter; left time: 3251.9303s\n",
      "\titers: 3600, epoch: 4 | loss: 0.2675755\n",
      "\tspeed: 0.1396s/iter; left time: 3240.3023s\n",
      "\titers: 3700, epoch: 4 | loss: 0.4497364\n",
      "\tspeed: 0.1395s/iter; left time: 3224.9383s\n",
      "\titers: 3800, epoch: 4 | loss: 0.2888970\n",
      "\tspeed: 0.1396s/iter; left time: 3213.2738s\n",
      "Epoch: 4 cost time: 535.4284415245056\n",
      "Epoch: 4, Steps: 3830 | Train Loss: 0.3124047 Vali Loss: 3.3161733 Test Loss: 1.6057121\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : weather_96_96_Autoformer_custom_ftM_sl96_ll48_pl96_dm512_nh8_el2_dl1_df2048_fc3_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 34983\n"
     ]
    }
   ],
   "source": [
    "!bash ./scripts/Weather_script/myAutoformer.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b523585-9739-4d9e-8868-66e4155be436",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
